{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":13106528,"sourceType":"datasetVersion","datasetId":8302288},{"sourceId":13439294,"sourceType":"datasetVersion","datasetId":8530229}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import cv2\nimport numpy as np\nimport os\nfrom glob import glob\nimport pandas as pd\nimport re\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras import layers,models","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-10T15:00:04.264544Z","iopub.execute_input":"2025-11-10T15:00:04.264875Z","iopub.status.idle":"2025-11-10T15:00:04.269446Z","shell.execute_reply.started":"2025-11-10T15:00:04.264852Z","shell.execute_reply":"2025-11-10T15:00:04.268784Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Inverted preprocess\ndef preprocess(input_image):\n    blurred = cv2.GaussianBlur(input_image, (5, 5), 0)\n    inverted = 255 - blurred  # Invert to make cells bright\n    equalized = cv2.equalizeHist(inverted)\n    equalized = cv2.equalizeHist(blurred)\n\n    return equalized\n\n# Analyze and annotate function\ndef analyze_and_annotate(img):\n    _, thresh = cv2.threshold(img, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n    contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n    annotated_img = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)\n    cv2.drawContours(annotated_img, contours, -1, (0, 255, 0), 2)\n    return thresh  # Return thresholded mask\n\n# Masking function\ndef mask_image(thresh, output_path, dataset_type='train'):\n    # Define mask directory based on dataset type\n    mask_dir = f'{dataset_type}/masks' if dataset_type in ['train', 'test'] else 'masks'\n    os.makedirs(mask_dir, exist_ok=True)\n    mask_path = os.path.join(mask_dir, os.path.basename(output_path).replace('.png', '_mask.png'))\n    cv2.imwrite(mask_path, thresh)\n    return mask_path\n\n# Function to extract sequence and timestamp\ndef extract_seq_time(path):\n    filename = os.path.basename(path)\n    seq_match = re.search(r'Phase_([A-D]\\d+_\\d+)', filename)\n    seq = seq_match.group(1) if seq_match else 'Unknown'\n    time_match = re.search(r'(\\d+)d(\\d+)h(\\d+)m', filename)\n    if time_match:\n        d, h, m = map(int, time_match.groups())\n        time_min = d * 1440 + h * 60 + m\n    else:\n        time_min = 0\n    return seq, time_min, path","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-10T15:00:04.270540Z","iopub.execute_input":"2025-11-10T15:00:04.271166Z","iopub.status.idle":"2025-11-10T15:00:04.288413Z","shell.execute_reply.started":"2025-11-10T15:00:04.271149Z","shell.execute_reply":"2025-11-10T15:00:04.287770Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# # Display the sorted DataFrame\n# print(\"\\nSorted DataFrame Summary:\")\n# display(df.head())\n# print(f\"\\nTotal entries: {len(df)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-10T15:00:04.289050Z","iopub.execute_input":"2025-11-10T15:00:04.289245Z","iopub.status.idle":"2025-11-10T15:00:04.307772Z","shell.execute_reply.started":"2025-11-10T15:00:04.289230Z","shell.execute_reply":"2025-11-10T15:00:04.307109Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# showing sorted images for verifying whether the images are sequential in order","metadata":{}},{"cell_type":"code","source":"import os\nimport cv2\nimport matplotlib.pyplot as plt\n\ndef show_mapping(dataset_type='test', start=0,number_of_images=0,iterate=1):\n    # Define directories based on dataset type in /kaggle/working/\n    if dataset_type == 'train':\n        data_dir = '/kaggle/input/analysed-data/train/original'  # Original images\n        processed_dir = '/kaggle/input/analysed-data/train/processed'\n        mask_dir = '/kaggle/input/analysed-data/train/masks'  # Mask images\n    elif dataset_type == 'test':\n        data_dir = '/kaggle/input/analysed-data/test/original'  # Assuming val data exists\n        processed_dir = '/kaggle/input/analysed-data/test/processed'\n        mask_dir = '/kaggle/input/analysed-data/test/masks'\n    else:\n        raise ValueError(\"dataset_type must be 'train' or 'test'\")\n\n    # Get paths from original images\n    paths = [os.path.join(data_dir, f) for f in os.listdir(data_dir) if f.endswith('.png')]\n\n    # Check if paths exist\n    if not paths:\n        print(f\"No {dataset_type} images found in {data_dir}.\")\n        return\n\n    # Sort paths to ensure consistent order (e.g., alphabetical)\n    paths.sort()\n\n    # Select first N images\n    paths = [paths[i] for i in range(start,number_of_images,iterate)]\n\n    for path in paths:\n        # Load original image\n        img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n        if img is None:\n            print(f\"Error loading original image: {path}\")\n            continue\n\n        # Load preprocessed image\n        filename = os.path.basename(path)\n        preprocessed_path = os.path.join(processed_dir, filename)\n        preprocessed = cv2.imread(preprocessed_path, cv2.IMREAD_GRAYSCALE)\n        if preprocessed is None:\n            print(f\"Error loading preprocessed image: {preprocessed_path}\")\n            continue\n\n        # Load mask image\n        mask_path = os.path.join(mask_dir, filename.replace('.png', '_mask.png'))\n        mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n        if mask is None:\n            print(f\"Error loading mask image: {mask_path}\")\n            continue\n\n        # Create and display plot\n        fig, axs = plt.subplots(1, 3, figsize=(15, 5))\n        axs[0].imshow(img, cmap='gray')\n        axs[0].set_title(f'Raw  Image')\n        axs[0].axis('off')\n        axs[1].imshow(preprocessed, cmap='gray')\n        axs[1].set_title(f'Preprocessed  ')\n        axs[1].axis('off')\n        axs[2].imshow(mask, cmap='gray')\n        axs[2].set_title(f' Masked')\n        axs[2].axis('off')\n        plt.show()\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-10T16:26:36.673015Z","iopub.execute_input":"2025-11-10T16:26:36.673273Z","iopub.status.idle":"2025-11-10T16:26:36.837900Z","shell.execute_reply.started":"2025-11-10T16:26:36.673250Z","shell.execute_reply":"2025-11-10T16:26:36.837315Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"show_mapping(dataset_type='train',start=0,number_of_images=70,iterate=4)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-10T16:26:39.787300Z","iopub.execute_input":"2025-11-10T16:26:39.787899Z","iopub.status.idle":"2025-11-10T16:26:46.106970Z","shell.execute_reply.started":"2025-11-10T16:26:39.787873Z","shell.execute_reply":"2025-11-10T16:26:46.106142Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# show_mapping('test',start=4 ,number_of_images=10)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-10T15:00:04.343036Z","iopub.execute_input":"2025-11-10T15:00:04.343273Z","iopub.status.idle":"2025-11-10T15:00:04.356754Z","shell.execute_reply.started":"2025-11-10T15:00:04.343258Z","shell.execute_reply":"2025-11-10T15:00:04.355986Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"modify and analyse masked data","metadata":{}},{"cell_type":"code","source":"import os\nimport numpy as np\nfrom glob import glob\nimport tensorflow as tf\n\n   \n# Path to your mask sequences\nmask_base_path = '/kaggle/input/analysed-data/combined_masks'\nclasses = ['B10_1', 'B10_2', 'C10_1', 'C10_2', 'D10_1', 'D10_2']\n\nprint(\"=== LOADING YOUR MASK DATA ===\")\n\n# Load all mask sequences\nall_sequences = []\nall_targets = []\n\nfor class_name in classes:\n    class_path = os.path.join(mask_base_path, class_name)\n    mask_files = sorted(glob(os.path.join(class_path, '*.png')))\n    \n    print(f\"{class_name}: {len(mask_files)} masks\")\n    \n    # Create sequences: 4 masks â†’ predict 5th mask\n    for i in range(len(mask_files) - 5):\n        # Input sequence (4 consecutive masks)\n        sequence = []\n        for j in range(4):\n            # Load and resize to 128x128\n            img = tf.keras.preprocessing.image.load_img(mask_files[i+j], color_mode='grayscale')\n            img = img.resize((128, 128))\n            img_array = tf.keras.preprocessing.image.img_to_array(img)\n            sequence.append(img_array)\n        \n        # Target (5th mask)\n        target_img = tf.keras.preprocessing.image.load_img(mask_files[i+4], color_mode='grayscale')\n        target_img = target_img.resize((128, 128))\n        target_array = tf.keras.preprocessing.image.img_to_array(target_img)\n        \n        all_sequences.append(np.array(sequence))\n        all_targets.append(target_array)\n\n# Convert to numpy arrays\nX = np.array(all_sequences).astype('float32') / 255.0\ny = np.array(all_targets).astype('float32') / 255.0\n\nprint(f\"X shape before reshape: {X.shape}\")\nprint(f\"y shape before reshape: {y.shape}\")\n\n# Reshape to correct dimensions\nX = X.reshape(-1, 4, 128, 128, 1)  # (samples, timesteps, height, width, channels)\ny = y.reshape(-1, 128, 128, 1)     # (samples, height, width, channels)\n\nprint(f\"Final X shape: {X.shape}\")\nprint(f\"Final y shape: {y.shape}\")\n\n# MOVE D10 TO TARGETS ONLY\nprint(\"\\n=== SEPARATING D10 FOR TESTING ===\")\n\n# Calculate samples per class\ntotal_samples = len(X)\nsamples_per_class = total_samples // 6\n\nprint(f\"Total samples: {total_samples}\")\nprint(f\"Samples per class: ~{samples_per_class}\")\n\n# Create indices for each condition\nb10_indices = list(range(0, samples_per_class * 2))  # B10_1 + B10_2\nc10_indices = list(range(samples_per_class * 2, samples_per_class * 4))  # C10_1 + C10_2  \nd10_indices = list(range(samples_per_class * 4, samples_per_class * 6))  # D10_1 + D10_2\n\nprint(f\"B10 samples: {len(b10_indices)}\")\nprint(f\"C10 samples: {len(c10_indices)}\")\nprint(f\"D10 samples: {len(d10_indices)}\")\n\n# Create training set (B10 + C10 only)\nX_train = np.concatenate([X[b10_indices], X[c10_indices]], axis=0)\ny_train = np.concatenate([y[b10_indices], y[c10_indices]], axis=0)\n\n# Create test set (D10 only)\nX_test = X[d10_indices]\ny_test = y[d10_indices]\n\nprint(f\"\\nTraining set (B10+C10): {X_train.shape}\")\nprint(f\"Test set (D10 only): {X_test.shape}\")\n\nprint(\"D10 moved to test targets only!\")\nprint(\"Training on B10+C10, Testing on D10\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-10T15:00:04.383782Z","iopub.execute_input":"2025-11-10T15:00:04.383978Z","iopub.status.idle":"2025-11-10T15:00:15.950073Z","shell.execute_reply.started":"2025-11-10T15:00:04.383964Z","shell.execute_reply":"2025-11-10T15:00:15.949324Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"segregate the data into training and testing data","metadata":{}},{"cell_type":"code","source":"X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-10T15:00:15.951276Z","iopub.execute_input":"2025-11-10T15:00:15.951521Z","iopub.status.idle":"2025-11-10T15:00:15.998864Z","shell.execute_reply.started":"2025-11-10T15:00:15.951504Z","shell.execute_reply":"2025-11-10T15:00:15.998225Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Generator Model\nuses convlstm2d,conv2d","metadata":{}},{"cell_type":"markdown","source":"","metadata":{},"attachments":{"ce9ed197-dbfb-4be5-9793-c48e1bff0027.png":{"image/png":"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"}}},{"cell_type":"code","source":"\nimport tensorflow as tf\nfrom tensorflow.keras import layers, Model, callbacks\nimport numpy as np\n\n# --- Your Generator ---\ngenerator_input = layers.Input(shape=(4, 128, 128, 1))\nx = layers.ConvLSTM2D(32, 3, padding='same', return_sequences=True, activation='relu')(generator_input)\nx = layers.Dropout(0.3)(x)\nx = layers.ConvLSTM2D(16, 3, padding='same', return_sequences=False, activation='relu')(x)\nx = layers.Dropout(0.3)(x)\nx = layers.Conv2D(32, 3, padding='same', activation='relu')(x)\nx = layers.Dropout(0.3)(x)\nx = layers.Conv2D(16, 3, padding='same', activation='relu')(x)\ngenerator_output = layers.Conv2D(1, 3, padding='same', activation='sigmoid')(x)\ngenerator = Model(generator_input, generator_output, name='Generator')\n\n# --- Your Discriminator ---\ndiscriminator_input = layers.Input(shape=(128, 128, 1))\nx = layers.Conv2D(32, 4, strides=2, padding='same')(discriminator_input)\nx = layers.LeakyReLU(0.2)(x)\nx = layers.Dropout(0.4)(x)\nx = layers.Conv2D(64, 4, strides=2, padding='same')(x)\nx = layers.LeakyReLU(0.2)(x)\nx = layers.Dropout(0.4)(x)\nx = layers.Conv2D(128, 4, strides=2, padding='same')(x)\nx = layers.LeakyReLU(0.2)(x)\nx = layers.Dropout(0.4)(x)\nx = layers.GlobalAveragePooling2D()(x)\ndiscriminator_output = layers.Dense(1, activation='sigmoid')(x)\ndiscriminator = Model(discriminator_input, discriminator_output, name='Discriminator')\n\n# --- Compile ---\ndiscriminator.compile(optimizer=tf.keras.optimizers.Adam(2e-4), loss='binary_crossentropy', metrics=['accuracy'])\ngenerator.compile(optimizer=tf.keras.optimizers.Adam(2e-4), loss='mean_absolute_error', metrics=['mse'])\n\nprint(\"Models ready!\")\nprint(f\"Generator: {generator.input_shape} â†’ {generator.output_shape}\")\nprint(f\"Discriminator: {discriminator.input_shape} â†’ {discriminator.output_shape}\")\n\n# --- Pre-train Generator (20 epochs) ---\nprint(\"\\nPre-training Generator (20 epochs)...\")\npre_history = generator.fit(\n    X_train, y_train,\n    batch_size=8,\n    epochs=20,\n    validation_data=(X_val, y_val),\n    callbacks=[\n        callbacks.EarlyStopping(patience=10, restore_best_weights=True),\n        callbacks.ReduceLROnPlateau(patience=5, factor=0.5, min_lr=1e-7),\n        callbacks.ModelCheckpoint('gen_pretrain.h5', save_best_only=True)\n    ],\n    verbose=1\n)\nprint(\"Pre-training complete!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-10T15:00:15.999579Z","iopub.execute_input":"2025-11-10T15:00:15.999796Z","iopub.status.idle":"2025-11-10T15:01:51.729499Z","shell.execute_reply.started":"2025-11-10T15:00:15.999780Z","shell.execute_reply":"2025-11-10T15:01:51.728935Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# create fake images to train discriminator first then train the generator","metadata":{}},{"cell_type":"code","source":"\n# --- Build GAN ---\ndiscriminator.trainable = False\ngan_input = layers.Input(shape=(4, 128, 128, 1))\nfake_frame = generator(gan_input)\ngan_output = discriminator(fake_frame)\ngan = Model(gan_input, gan_output)\ngan.compile(optimizer=tf.keras.optimizers.Adam(2e-4), loss='binary_crossentropy')\n\ndiscriminator.trainable = True\n\n# --- Training Loop (50 epochs) ---\nprint(\"\\nGAN Training: Epochs 21â€“70\")\nd_losses, g_losses, mae_losses = [], [], []\n\nfor epoch in range(50):\n    idx = np.random.randint(0, X_train.shape[0], 8)\n    real_prev = X_train[idx]\n    real_next = y_train[idx]\n    \n    # Train Discriminator\n    fake_next = generator.predict(real_prev, verbose=0)\n    real_labels = np.ones((8, 1)) * 0.9\n    fake_labels = np.zeros((8, 1))\n    \n    d_loss_real = discriminator.train_on_batch(real_next, real_labels)\n    d_loss_fake = discriminator.train_on_batch(fake_next, fake_labels)\n    d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n    \n    # Train Generator\n    g_loss = gan.train_on_batch(real_prev, np.ones((8, 1)))\n    \n    mae = np.mean(np.abs(fake_next - real_next))\n    \n    d_losses.append(d_loss[0])\n    g_losses.append(g_loss)\n    mae_losses.append(mae)\n    \n    if epoch % 10 == 0:\n        print(f\"  Epoch {21+epoch} | D: {d_loss[0]:.4f} | G: {g_loss:.4f} | MAE: {mae:.4f}\")\n\n# Save checkpoint\ngenerator.save('gan_section1.h5')\nprint(\"Section 1 complete! Model saved.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-10T15:01:51.730449Z","iopub.execute_input":"2025-11-10T15:01:51.730996Z","iopub.status.idle":"2025-11-10T15:02:15.498160Z","shell.execute_reply.started":"2025-11-10T15:01:51.730977Z","shell.execute_reply":"2025-11-10T15:02:15.497539Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n\nprint(\"\\nGAN Training: Epochs 71â€“120\")\n\nfor epoch in range(50):\n    idx = np.random.randint(0, X_train.shape[0], 8)\n    real_prev = X_train[idx]\n    real_next = y_train[idx]\n    \n    fake_next = generator.predict(real_prev, verbose=0)\n    real_labels = np.ones((8, 1)) * 0.9\n    fake_labels = np.zeros((8, 1))\n    \n    d_loss_real = discriminator.train_on_batch(real_next, real_labels)\n    d_loss_fake = discriminator.train_on_batch(fake_next, fake_labels)\n    d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n    \n    g_loss = gan.train_on_batch(real_prev, np.ones((8, 1)))\n    \n    mae = np.mean(np.abs(fake_next - real_next))\n    \n    if epoch % 10 == 0:\n        print(f\"  Epoch {71+epoch} | D: {d_loss[0]:.4f} | G: {g_loss:.4f} | MAE: {mae:.4f}\")\n\ngenerator.save('gan_section2.h5')\nprint(\"Section 2 complete! Model saved.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-10T15:02:15.500070Z","iopub.execute_input":"2025-11-10T15:02:15.500284Z","iopub.status.idle":"2025-11-10T15:02:23.658366Z","shell.execute_reply.started":"2025-11-10T15:02:15.500268Z","shell.execute_reply":"2025-11-10T15:02:23.657786Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n\nprint(\"\\nGAN Training: Epochs 121â€“170\")\n\nfor epoch in range(50):\n    idx = np.random.randint(0, X_train.shape[0], 8)\n    real_prev = X_train[idx]\n    real_next = y_train[idx]\n    \n    fake_next = generator.predict(real_prev, verbose=0)\n    real_labels = np.ones((8, 1)) * 0.9\n    fake_labels = np.zeros((8, 1))\n    \n    d_loss_real = discriminator.train_on_batch(real_next, real_labels)\n    d_loss_fake = discriminator.train_on_batch(fake_next, fake_labels)\n    d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n    \n    g_loss = gan.train_on_batch(real_prev, np.ones((8, 1)))\n    \n    mae = np.mean(np.abs(fake_next - real_next))\n    \n    if epoch % 10 == 0:\n        print(f\"  Epoch {121+epoch} | D: {d_loss[0]:.4f} | G: {g_loss:.4f} | MAE: {mae:.4f}\")\n\ngenerator.save('gan_section3.h5')\nprint(\"Section 3 complete!\")\n\n# --- Final Fine-tuning (30 epochs) ---\nprint(\"\\nFinal Fine-tuning: Epochs 171â€“200\")\ngenerator.compile(\n    optimizer=tf.keras.optimizers.Adam(1e-4),  # Lower LR\n    loss='mean_absolute_error',\n    metrics=['mse']\n)\n\nfine_history = generator.fit(\n    X_train, y_train,\n    batch_size=8,\n    epochs=30,\n    validation_data=(X_val, y_val),\n    callbacks=[\n        callbacks.EarlyStopping(patience=8, restore_best_weights=True),\n        callbacks.ReduceLROnPlateau(patience=5, factor=0.5, min_lr=1e-7),\n        callbacks.ModelCheckpoint('final_generator.h5', save_best_only=True)\n    ],\n    verbose=1\n)\n\nprint(\"200 EPOCHS COMPLETE!\")\ngenerator.save('livecell_gan_200epochs_final.h5')\nprint(\"FINAL MODEL SAVED: livecell_gan_200epochs_final.h5\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-10T15:02:23.659015Z","iopub.execute_input":"2025-11-10T15:02:23.659191Z","iopub.status.idle":"2025-11-10T15:03:38.818236Z","shell.execute_reply.started":"2025-11-10T15:02:23.659177Z","shell.execute_reply":"2025-11-10T15:03:38.817652Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\nfrom skimage.metrics import structural_similarity as ssim\npred = generator.predict(X_val, verbose=0)\npred = np.clip(pred, 0, 1)\ny_val_norm = np.clip(y_val, 0, 1)\n\nmae = np.mean(np.abs(pred - y_val_norm))\nmse = np.mean((pred - y_val_norm)**2)\nssim_vals = [ssim(y_val_norm[i,...,0], pred[i,...,0], data_range=1.0) for i in range(len(pred))]\nssim_mean = np.mean(ssim_vals)\n\nprint(f\"FINAL â†’ MAE: {mae:.4f} | MSE: {mse:.4f} | SSIM: {ssim_mean:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-10T15:03:38.819011Z","iopub.execute_input":"2025-11-10T15:03:38.819259Z","iopub.status.idle":"2025-11-10T15:03:41.216467Z","shell.execute_reply.started":"2025-11-10T15:03:38.819232Z","shell.execute_reply":"2025-11-10T15:03:41.215708Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"=== growth CAPABILITY ANALYSIS ===\")\n\n# 1. PREDICT ON ALL VALIDATION DATA\nprint(\"Generating predictions for analysis...\")\nval_predictions = generator.predict(X_val, batch_size=4)\n\n# 2. CALCULATE growth METRICS FOR EACH SAMPLE\ngrowth_metrics = []\n\nfor i in range(len(X_val)):\n    # Get frames\n    last_frame = X_val[i, -1, :, :, 0]\n    predicted_frame = val_predictions[i, :, :, 0] \n    actual_frame = y_val[i, :, :, 0]\n    \n    # Calculate growth maps\n    predicted_growth = np.abs(predicted_frame - last_frame)\n    actual_growth = np.abs(actual_frame - last_frame)\n    \n    # Create masks for significant growth\n    pred_mask = (predicted_growth > 0.1).astype(np.float32)\n    actual_mask = (actual_growth > 0.1).astype(np.float32)\n    \n    # Calculate overlap\n    overlap = np.sum(pred_mask * actual_mask)\n    union = np.sum((pred_mask + actual_mask) > 0)\n    \n    # Store metrics\n    metrics = {\n        'predicted_area': np.sum(pred_mask),\n        'actual_area': np.sum(actual_mask),\n        'predicted_intensity': np.mean(predicted_growth),\n        'actual_intensity': np.mean(actual_growth),\n        'iou': overlap / union if union > 0 else 0\n    }\n    growth_metrics.append(metrics)\n\n# 3. CALCULATE OVERALL STATISTICS\npredicted_areas = [m['predicted_area'] for m in growth_metrics]\nactual_areas = [m['actual_area'] for m in growth_metrics]\npredicted_intensities = [m['predicted_intensity'] for m in growth_metrics]\nactual_intensities = [m['actual_intensity'] for m in growth_metrics]\nious = [m['iou'] for m in growth_metrics]\n\nprint(\"\\n=== growth ANALYSIS RESULTS ===\")\nprint(f\"Average Predicted growth Area: {np.mean(predicted_areas):.1f} pixels\")\nprint(f\"Average Actual growth Area: {np.mean(actual_areas):.1f} pixels\")\nprint(f\"Average Predicted Intensity: {np.mean(predicted_intensities):.4f}\")\nprint(f\"Average Actual Intensity: {np.mean(actual_intensities):.4f}\")\nprint(f\"Average IoU (Overlap): {np.mean(ious):.4f}\")\n\n# 4. COMPARE DIFFERENT CLASSES\nprint(\"\\n=== growth BY CLASS TYPE ===\")\nclass_growth = {}\n\nfor i, class_type in enumerate(['B10', 'C10', 'D10']):\n    # Find samples from this class (simplified - you'd need actual class labels)\n    class_indices = [j for j in range(len(X_val)) if j % 3 == i]\n    \n    if class_indices:\n        class_ious = [ious[j] for j in class_indices]\n        class_intensities = [actual_intensities[j] for j in class_indices]\n        \n        print(f\"{class_type}:\")\n        print(f\"  IoU: {np.mean(class_ious):.4f}\")\n        print(f\"  Intensity: {np.mean(class_intensities):.4f}\")\n\n# 5. VISUALIZE SAMPLE RESULTS\nimport matplotlib.pyplot as plt\n\nprint(\"\\n=== SAMPLE VISUALIZATION ===\")\nsample_idx = 0\n\nlast_frame = X_val[sample_idx, -1, :, :, 0]\npredicted_frame = val_predictions[sample_idx, :, :, 0]\nactual_frame = y_val[sample_idx, :, :, 0]\n\nfig, axes = plt.subplots(2, 3, figsize=(15, 10))\n\n# Row 1: Frames\naxes[0,0].imshow(last_frame, cmap='gray')\naxes[0,0].set_title('Last Input Frame')\naxes[0,0].axis('off')\n\naxes[0,1].imshow(predicted_frame, cmap='gray')\naxes[0,1].set_title('Predicted Next Frame')\naxes[0,1].axis('off')\n\naxes[0,2].imshow(actual_frame, cmap='gray')\naxes[0,2].set_title('Actual Next Frame')\naxes[0,2].axis('off')\n\n# Row 2: growth Maps\npred_growth = np.abs(predicted_frame - last_frame)\nactual_growth = np.abs(actual_frame - last_frame)\n\naxes[1,0].imshow(pred_growth, cmap='hot')\naxes[1,0].set_title('Predicted growth')\naxes[1,0].axis('off')\n\naxes[1,1].imshow(actual_growth, cmap='hot')\naxes[1,1].set_title('Actual growth')\naxes[1,1].axis('off')\n\n# Overlap\noverlap = (pred_growth > 0.1) & (actual_growth > 0.1)\naxes[1,2].imshow(overlap, cmap='RdYlGn')\naxes[1,2].set_title('growth Overlap\\n(Green = Correct Prediction)')\naxes[1,2].axis('off')\n\nplt.tight_layout()\nplt.show()\n\nprint(\"\\n=== growth CAPABILITY SUMMARY ===\")\nprint(\"Model can predict growth areas\")\nprint(\"Quantitative metrics available\")\nprint(\"Ready for biological analysis\")\nprint(f\"Prediction accuracy: {np.mean(ious)*100:.1f}% overlap\")\n\n# Save analysis results\nnp.save('/kaggle/working/growth_predictions.npy', val_predictions)\nnp.save('/kaggle/working/growth_metrics.npy', growth_metrics)\nprint(\"Analysis results saved!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-10T15:03:41.217399Z","iopub.execute_input":"2025-11-10T15:03:41.217616Z","iopub.status.idle":"2025-11-10T15:03:42.070387Z","shell.execute_reply.started":"2025-11-10T15:03:41.217600Z","shell.execute_reply":"2025-11-10T15:03:42.069817Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# SHOW SAMPLE IMAGES FIRST\nprint(\"=== SAMPLE IMAGES FROM YOUR DATA ===\")\n\n# Show first sequence\nsample_idx = 0\nsample_sequence = X_val[sample_idx]  # 4 frames\nsample_target = y_val[sample_idx]    # target frame\n\nprint(f\"Sample sequence shape: {sample_sequence.shape}\")\nprint(f\"Sample target shape: {sample_target.shape}\")\n\nimport matplotlib.pyplot as plt\n\n# Show the 4 input frames and target\nfig, axes = plt.subplots(1, 5, figsize=(20, 4))\n\n# Input frames\nfor i in range(4):\n    axes[i].imshow(sample_sequence[i, :, :, 0], cmap='gray')\n    axes[i].set_title(f'Input Frame {i+1}')\n    axes[i].axis('off')\n\n# Target frame\naxes[4].imshow(sample_target[:, :, 0], cmap='gray')\naxes[4].set_title('Target Frame (Next)')\naxes[4].axis('off')\n\nplt.tight_layout()\nplt.show()\n\nprint(\"Image values range:\")\nprint(f\"Input frames: [{sample_sequence.min():.3f}, {sample_sequence.max():.3f}]\")\nprint(f\"Target frame: [{sample_target.min():.3f}, {sample_target.max():.3f}]\")\n\n# Now show what the model predicts\nprint(\"\\n=== MODEL PREDICTION ===\")\nsample_input = X_val[sample_idx:sample_idx+1]  # Keep batch dimension\nprediction = generator.predict(sample_input, batch_size=1)\n\nfig, axes = plt.subplots(1, 3, figsize=(15, 5))\n\n# Last input frame\naxes[0].imshow(sample_sequence[3, :, :, 0], cmap='gray')\naxes[0].set_title('Last Input Frame')\naxes[0].axis('off')\n\n# Model prediction\naxes[1].imshow(prediction[0, :, :, 0], cmap='gray')\naxes[1].set_title('Model Prediction')\naxes[1].axis('off')\n\n# Actual target\naxes[2].imshow(sample_target[:, :, 0], cmap='gray')\naxes[2].set_title('Actual Target')\naxes[2].axis('off')\n\nplt.tight_layout()\nplt.show()\n\nprint(\"Prediction vs Actual:\")\nprint(f\"Prediction range: [{prediction.min():.3f}, {prediction.max():.3f}]\")\nprint(f\"Actual range: [{sample_target.min():.3f}, {sample_target.max():.3f}]\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-10T15:03:42.071034Z","iopub.execute_input":"2025-11-10T15:03:42.071212Z","iopub.status.idle":"2025-11-10T15:03:43.427036Z","shell.execute_reply.started":"2025-11-10T15:03:42.071197Z","shell.execute_reply":"2025-11-10T15:03:43.426107Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Fine-Tuning & Analysis on `/kaggle/working/livecell_gan_200epochs_final.h5`\n\n# Load your final trained model\ngenerator = tf.keras.models.load_model('/kaggle/working/livecell_gan_200epochs_final.h5')\nprint(\"Loaded: livecell_gan_200epochs_final.h5\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-10T15:03:43.428525Z","iopub.execute_input":"2025-11-10T15:03:43.428832Z","iopub.status.idle":"2025-11-10T15:03:43.509511Z","shell.execute_reply.started":"2025-11-10T15:03:43.428808Z","shell.execute_reply":"2025-11-10T15:03:43.508958Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# # FINE-TUNE THE MODEL\n# print(\"=== FINE-TUNING THE GENERATOR ===\")\n\n# # 1. Use a lower learning rate for fine-tuning\n# fine_tune_optimizer = tf.keras.optimizers.Adam(2e-4)  # Much lower learning rate\n# generator.compile(\n#     optimizer=fine_tune_optimizer,\n#     loss='mean_absolute_error',\n#     metrics=['accuracy']\n# )\n\n# # 2. Train with all data (not just subset)\n# print(\"Fine-tuning with all training data...\")\n# fine_tune_history = generator.fit(\n#     X_train, y_train,  # Use ALL training data\n#     batch_size=8,      # Small batches for stability\n#     epochs=40,         # More epochs for fine-tuning\n#     validation_data=(X_val, y_val),\n#     verbose=1,\n#     callbacks=[\n#         tf.keras.callbacks.EarlyStopping(patience=8, restore_best_weights=True),\n#         tf.keras.callbacks.ReduceLROnPlateau(patience=5, factor=0.5, min_lr=1e-7)\n#     ]\n# )\n\n# print(\"Fine-tuning completed!\")\n\n# # 3. EVALUATE AFTER FINE-TUNING\n# print(\"\\n=== EVALUATION AFTER FINE-TUNING ===\")\n# test_predictions_fine = generator.predict(X_val[:8])  # Only 8 samples for comparison\n\n# # Calculate new metrics (only on the 8 samples we predicted)\n# mse_fine = np.mean((test_predictions_fine - y_val[:8]) ** 2)\n# mae_fine = np.mean(np.abs(test_predictions_fine - y_val[:8]))\n\n# print(\"BEFORE vs AFTER Fine-tuning (on 8 samples):\")\n# print(f\"MSE:  {mse:.4f} â†’ {mse_fine:.4f}\")\n# print(f\"MAE:  {mae:.4f} â†’ {mae_fine:.4f}\")\n\n# # 4. VISUALIZE IMPROVEMENT\n# fig, axes = plt.subplots(2, 4, figsize=(20, 10))\n\n# for i in range(4):\n#     # Before fine-tuning\n#     axes[0, i].imshow(test_predictions[i, :, :, 0], cmap='gray')\n#     axes[0, i].set_title(f'Before FT - Sample {i+1}')\n#     axes[0, i].axis('off')\n    \n#     # After fine-tuning\n#     axes[1, i].imshow(test_predictions_fine[i, :, :, 0], cmap='gray')\n#     axes[1, i].set_title(f'After FT - Sample {i+1}')\n#     axes[1, i].axis('off')\n\n# plt.suptitle('Before vs After Fine-tuning')\n# plt.tight_layout()\n# plt.show()\n\n# # 5. growth ANALYSIS AFTER FINE-TUNING (ONLY 8 SAMPLES)\n# print(\"\\n=== growth ANALYSIS AFTER FINE-TUNING ===\")\n\n# growth_metrics_fine = []\n\n# for i in range(8):  # Only 8 samples we predicted\n#     last_frame = X_val[i, -1, :, :, 0]\n#     predicted_frame = test_predictions_fine[i, :, :, 0]\n#     actual_frame = y_val[i, :, :, 0]\n    \n#     predicted_growth = np.abs(predicted_frame - last_frame)\n#     actual_growth = np.abs(actual_frame - last_frame)\n    \n#     pred_mask = (predicted_growth > 0.1).astype(np.float32)\n#     actual_mask = (actual_growth > 0.1).astype(np.float32)\n    \n#     overlap = np.sum(pred_mask * actual_mask)\n#     union = np.sum((pred_mask + actual_mask) > 0)\n    \n#     metrics = {\n#         'predicted_area': np.sum(pred_mask),\n#         'actual_area': np.sum(actual_mask),\n#         'iou': overlap / union if union > 0 else 0\n#     }\n#     growth_metrics_fine.append(metrics)\n\n# ious_fine = [m['iou'] for m in growth_metrics_fine]\n\n# print(\"growth Overlap (IoU) - 8 samples:\")\n# print(f\"Before fine-tuning: {np.mean(ious):.4f}\")\n# print(f\"After fine-tuning:  {np.mean(ious_fine):.4f}\")\n# print(f\"Improvement: {((np.mean(ious_fine) - np.mean(ious)) / np.mean(ious) * 100):.1f}%\")\n\n# # 6. SAVE FINE-TUNED MODEL\n# generator.save('/kaggle/working/fine_tuned_growth_generator.h5')\n# print(\"Fine-tuned model saved!\")\n\n# # 7. TEST ON YOUR SPECIFIC IMAGE AGAIN\n# print(\"\\n=== TESTING FINE-TUNED MODEL ON YOUR IMAGE ===\")\n\n# # Make prediction with fine-tuned model\n# fine_prediction = generator.predict(input_sequence)\n\n# # Compare results\n# fig, axes = plt.subplots(1, 4, figsize=(20, 5))\n\n# axes[0].imshow(input_sequence[0, -1, :, :, 0], cmap='gray')\n# axes[0].set_title('Last Input Frame')\n# axes[0].axis('off')\n\n# axes[1].imshow(prediction[0, :, :, 0], cmap='gray')\n# axes[1].set_title('Before Fine-tuning')\n# axes[1].axis('off')\n\n# axes[2].imshow(fine_prediction[0, :, :, 0], cmap='gray')\n# axes[2].set_title('After Fine-tuning')\n# axes[2].axis('off')\n\n# axes[3].imshow(target_array[:, :, 0], cmap='gray')\n# axes[3].set_title('Actual Target')\n# axes[3].axis('off')\n\n# plt.tight_layout()\n# plt.show()\n\n# print(\"Fine-tuning complete! Model should be more accurate now.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-10T15:03:43.510322Z","iopub.execute_input":"2025-11-10T15:03:43.510572Z","iopub.status.idle":"2025-11-10T15:03:43.515816Z","shell.execute_reply.started":"2025-11-10T15:03:43.510551Z","shell.execute_reply":"2025-11-10T15:03:43.515212Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"=== NEXT STEPS FOR growth ANALYSIS ===\")\n\n# 1. QUANTITATIVE growth METRICS \nprint(\"1. Calculating growth metrics...\")\n\n# Predict on all validation data\nall_predictions = generator.predict(X_val, batch_size=4)\n\ngrowth_results = []\n\nfor i in range(len(X_val)):\n    # Get frames\n    last_frame = X_val[i, -1, :, :, 0]\n    predicted = all_predictions[i, :, :, 0]\n    actual = y_val[i, :, :, 0]\n    \n    # Calculate growth changes\n    pred_growth = np.abs(predicted - last_frame)\n    actual_growth = np.abs(actual - last_frame)\n    \n    # Threshold to identify significant growth\n    pred_mask = (pred_growth > 0.15).astype(np.float32)\n    actual_mask = (actual_growth > 0.15).astype(np.float32)\n    \n    # Calculate metrics\n    overlap = np.sum(pred_mask * actual_mask)\n    union = np.sum((pred_mask + actual_mask) > 0)\n    \n    growth_results.append({\n        'sample_id': i,\n        'predicted_growth_area': float(np.sum(pred_mask)),  # Convert to Python float\n        'actual_growth_area': float(np.sum(actual_mask)),   # Convert to Python float\n        'predicted_intensity': float(np.mean(pred_growth)), # Convert to Python float\n        'actual_intensity': float(np.mean(actual_growth)),  # Convert to Python float\n        'iou': float(overlap / union if union > 0 else 0),  # Convert to Python float\n        'precision': float(overlap / np.sum(pred_mask) if np.sum(pred_mask) > 0 else 0),\n        'recall': float(overlap / np.sum(actual_mask) if np.sum(actual_mask) > 0 else 0)\n    })\n\n# 2. OVERALL PERFORMANCE\nprint(\"\\n2. Overall growth Prediction Performance:\")\nious = [r['iou'] for r in growth_results]\nprecisions = [r['precision'] for r in growth_results]\nrecalls = [r['recall'] for r in growth_results]\n\nprint(f\"Average IoU (Overlap): {np.mean(ious):.3f}\")\nprint(f\"Average Precision: {np.mean(precisions):.3f}\")\nprint(f\"Average Recall: {np.mean(recalls):.3f}\")\nprint(f\"F1-Score: {2 * (np.mean(precisions) * np.mean(recalls)) / (np.mean(precisions) + np.mean(recalls)):.3f}\")\n\n# 3. COMPARE DIFFERENT CONDITIONS\nprint(\"\\n3. growth by Condition (B10 vs C10 vs D10):\")\n# Assuming samples are ordered by class\nsamples_per_class = len(X_val) // 3\n\nfor i, condition in enumerate(['B10', 'C10', 'D10']):\n    start_idx = i * samples_per_class\n    end_idx = (i + 1) * samples_per_class\n    \n    condition_ious = ious[start_idx:end_idx]\n    condition_intensities = [r['actual_intensity'] for r in growth_results[start_idx:end_idx]]\n    \n    print(f\"{condition}:\")\n    print(f\"  IoU: {np.mean(condition_ious):.3f}\")\n    print(f\"  Growth Intensity: {np.mean(condition_intensities):.4f}\")\n    print(f\"  Samples: {len(condition_ious)}\")\n\n# 4. VISUALIZE BEST/WORST PREDICTIONS\nprint(\"\\n4. Analyzing prediction quality range...\")\n\n# Sort by IoU to find best and worst predictions\ngrowth_results.sort(key=lambda x: x['iou'], reverse=True)\n\nprint(\"Best predictions (High IoU):\")\nfor i in range(3):\n    print(f\"  Sample {growth_results[i]['sample_id']}: IoU = {growth_results[i]['iou']:.3f}\")\n\nprint(\"Worst predictions (Low IoU):\")\nfor i in range(1, 4):\n    print(f\"  Sample {growth_results[-i]['sample_id']}: IoU = {growth_results[-i]['iou']:.3f}\")\n\n# 5. SAVE RESULTS FOR PAPER/REPORT\nprint(\"\\n5. Saving analysis results...\")\nimport pandas as pd\nimport json\n\n# Convert to DataFrame\nresults_df = pd.DataFrame(growth_results)\nresults_df.to_csv('/kaggle/working/growth_analysis_results.csv', index=False)\n\n# Save summary statistics (convert all to Python native types)\nsummary_stats = {\n    'mean_iou': float(np.mean(ious)),\n    'mean_precision': float(np.mean(precisions)),\n    'mean_recall': float(np.mean(recalls)),\n    'total_samples': len(X_val),\n    'model_type': 'ConvLSTM_Generator'\n}\n\nwith open('/kaggle/working/growth_summary.json', 'w') as f:\n    json.dump(summary_stats, f, indent=2)\n\nprint(\" Analysis complete! Results saved.\")\nprint(\"\\n NEXT STEPS FOR YOUR RESEARCH:\")\nprint(\"1. Use the CSV file for statistical analysis\")\nprint(\"2. Create plots from the results\")\nprint(\"3. Compare different conditions (B10 vs C10 vs D10)\")\nprint(\"4. Calculate statistical significance\")\nprint(\"5. Write up your growth capability findings\")\n\nprint(f\"\\n Your model successfully predicts growth with {np.mean(ious)*100:.1f}% overlap accuracy!\")\n\n# Show sample of the saved data\nprint(\"\\nSample of saved results:\")\nprint(results_df.head())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-10T15:03:43.516692Z","iopub.execute_input":"2025-11-10T15:03:43.516934Z","iopub.status.idle":"2025-11-10T15:03:46.109703Z","shell.execute_reply.started":"2025-11-10T15:03:43.516910Z","shell.execute_reply":"2025-11-10T15:03:46.108977Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"# Fine-Tuning & Analysis on `/kaggle/working/livecell_gan_200epochs_final.h5`\n\n# Load your final trained model\ngenerator = tf.keras.models.load_model('/kaggle/working/livecell_gan_200epochs_final.h5')\nprint(\"Loaded: livecell_gan_200epochs_final.h5\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-10T15:03:46.110564Z","iopub.execute_input":"2025-11-10T15:03:46.111316Z","iopub.status.idle":"2025-11-10T15:03:46.186336Z","shell.execute_reply.started":"2025-11-10T15:03:46.111291Z","shell.execute_reply":"2025-11-10T15:03:46.185682Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# TEST THE MODEL ON TEST DATA (D10 only)\nprint(\"=== TESTING MODEL ON D10 TEST DATA ===\")\n\n# Test on 6 different samples from D10 test set\ntest_indices = [0, 5, 10, 15, 20, 25]  # Different D10 samples\n\nfig, axes = plt.subplots(6, 4, figsize=(20, 25))\n\nfor row, idx in enumerate(test_indices):\n    # Get the sequence from D10 test data\n    input_sequence = X_test[idx:idx+1]\n    prediction = generator.predict(input_sequence, batch_size=1)\n    \n    # Get frames from D10 test data\n    frame_1 = input_sequence[0, 0, :, :, 0]  # First frame\n    frame_2 = input_sequence[0, 1, :, :, 0]  # Second frame  \n    frame_3 = input_sequence[0, 2, :, :, 0]  # Third frame\n    last_frame = input_sequence[0, 3, :, :, 0]  # Last input frame\n    predicted_frame = prediction[0, :, :, 0]  # Predicted frame\n    actual_frame = y_test[idx, :, :, 0]  # Actual target from D10\n    \n    # Row 1: Show input sequence progression\n    axes[row, 0].imshow(frame_1, cmap='gray')\n    axes[row, 0].set_title(f'D10 Sample {idx}\\nFrame 1')\n    axes[row, 0].axis('off')\n    \n    axes[row, 1].imshow(frame_2, cmap='gray')\n    axes[row, 1].set_title('Frame 2')\n    axes[row, 1].axis('off')\n    \n    axes[row, 2].imshow(frame_3, cmap='gray')\n    axes[row, 2].set_title('Frame 3')\n    axes[row, 2].axis('off')\n    \n    axes[row, 3].imshow(last_frame, cmap='gray')\n    axes[row, 3].set_title('Frame 4 (Last Input)')\n    axes[row, 3].axis('off')\n\nplt.tight_layout()\nplt.show()\n\n# Show predictions vs actual for D10\nfig, axes = plt.subplots(6, 3, figsize=(18, 25))\n\nfor row, idx in enumerate(test_indices):\n    input_sequence = X_test[idx:idx+1]\n    prediction = generator.predict(input_sequence, batch_size=1)\n    \n    last_frame = input_sequence[0, 3, :, :, 0]\n    predicted_frame = prediction[0, :, :, 0]\n    actual_frame = y_test[idx, :, :, 0]\n    \n    # Calculate growth maps\n    pred_growth = np.abs(predicted_frame - last_frame)\n    actual_growth = np.abs(actual_frame - last_frame)\n    \n    # Column 1: Last input frame\n    axes[row, 0].imshow(last_frame, cmap='gray')\n    axes[row, 0].set_title(f'D10 Sample {idx}\\nLast Input Frame')\n    axes[row, 0].axis('off')\n    \n    # Column 2: Model prediction\n    axes[row, 1].imshow(predicted_frame, cmap='gray')\n    \n    # Calculate metrics for this D10 sample\n    pred_mask = (pred_growth > 0.15).astype(np.float32)\n    actual_mask = (actual_growth > 0.15).astype(np.float32)\n    overlap = np.sum(pred_mask * actual_mask)\n    union = np.sum((pred_mask + actual_mask) > 0)\n    iou = overlap / union if union > 0 else 0\n    \n    axes[row, 1].set_title(f'Predicted Frame\\nIoU: {iou:.3f}')\n    axes[row, 1].axis('off')\n    \n    # Column 3: Actual target\n    axes[row, 2].imshow(actual_frame, cmap='gray')\n    axes[row, 2].set_title('Actual D10 Target Frame')\n    axes[row, 2].axis('off')\n\nplt.tight_layout()\nplt.show()\n\n# Show growth heatmaps for D10\nprint(\"\\n=== D10 growth HEATMAPS ===\")\nfig, axes = plt.subplots(6, 3, figsize=(18, 25))\n\nfor row, idx in enumerate(test_indices):\n    input_sequence = X_test[idx:idx+1]\n    prediction = generator.predict(input_sequence, batch_size=1)\n    \n    last_frame = input_sequence[0, 3, :, :, 0]\n    predicted_frame = prediction[0, :, :, 0]\n    actual_frame = y_test[idx, :, :, 0]\n    \n    # Calculate growth\n    pred_growth = np.abs(predicted_frame - last_frame)\n    actual_growth = np.abs(actual_frame - last_frame)\n    \n    # Column 1: Predicted growth\n    im1 = axes[row, 0].imshow(pred_growth, cmap='hot')\n    axes[row, 0].set_title(f'D10 Sample {idx}\\nPredicted growth')\n    axes[row, 0].axis('off')\n    plt.colorbar(im1, ax=axes[row, 0], fraction=0.046)\n    \n    # Column 2: Actual growth  \n    im2 = axes[row, 1].imshow(actual_growth, cmap='hot')\n    axes[row, 1].set_title('Actual growth')\n    axes[row, 1].axis('off')\n    plt.colorbar(im2, ax=axes[row, 1], fraction=0.046)\n    \n    # Column 3: Overlap\n    pred_mask = (pred_growth > 0.15).astype(bool)\n    actual_mask = (actual_growth > 0.15).astype(bool)\n    \n    # Create overlap visualization\n    overlap_viz = np.zeros((128, 128, 3))\n    overlap_viz[pred_mask & actual_mask] = [0, 1, 0]  # Green = correct prediction\n    overlap_viz[pred_mask & ~actual_mask] = [1, 0, 0]  # Red = false positive\n    overlap_viz[~pred_mask & actual_mask] = [0, 0, 1]  # Blue = false negative\n    \n    axes[row, 2].imshow(overlap_viz)\n    axes[row, 2].set_title('Overlap Analysis\\n(Green=Correct, Red=FP, Blue=FN)')\n    axes[row, 2].axis('off')\n\nplt.tight_layout()\nplt.show()\n\n# Print detailed metrics for each D10 test sample\nprint(\"\\n=== DETAILED METRICS FOR D10 TEST SAMPLES ===\")\nd10_ious = []\nd10_precisions = []\nd10_recalls = []\n\nfor idx in test_indices:\n    input_sequence = X_test[idx:idx+1]\n    prediction = generator.predict(input_sequence, batch_size=1)\n    \n    last_frame = input_sequence[0, 3, :, :, 0]\n    predicted_frame = prediction[0, :, :, 0]\n    actual_frame = y_test[idx, :, :, 0]\n    \n    pred_growth = np.abs(predicted_frame - last_frame)\n    actual_growth = np.abs(actual_frame - last_frame)\n    \n    pred_mask = (pred_growth > 0.15).astype(np.float32)\n    actual_mask = (actual_growth > 0.15).astype(np.float32)\n    \n    overlap = np.sum(pred_mask * actual_mask)\n    union = np.sum((pred_mask + actual_mask) > 0)\n    iou = overlap / union if union > 0 else 0\n    precision = overlap / np.sum(pred_mask) if np.sum(pred_mask) > 0 else 0\n    recall = overlap / np.sum(actual_mask) if np.sum(actual_mask) > 0 else 0\n    \n    d10_ious.append(iou)\n    d10_precisions.append(precision)\n    d10_recalls.append(recall)\n    \n    print(f\"D10 Sample {idx}:\")\n    print(f\"  IoU: {iou:.3f}\")\n    print(f\"  Precision: {precision:.3f}\")\n    print(f\"  Recall: {recall:.3f}\")\n    print(f\"  Predicted growth area: {np.sum(pred_mask):.0f} pixels\")\n    print(f\"  Actual growth area: {np.sum(actual_mask):.0f} pixels\")\n    print()\n\nprint(f\"\\n=== D10 TEST SUMMARY ===\")\nprint(f\"Average IoU: {np.mean(d10_ious):.3f} Â± {np.std(d10_ious):.3f}\")\nprint(f\"Average Precision: {np.mean(d10_precisions):.3f} Â± {np.std(d10_precisions):.3f}\")\nprint(f\"Average Recall: {np.mean(d10_recalls):.3f} Â± {np.std(d10_recalls):.3f}\")\nprint(f\"F1-Score: {2 * (np.mean(d10_precisions) * np.mean(d10_recalls)) / (np.mean(d10_precisions) + np.mean(d10_recalls)):.3f}\")\n\nprint(\"ðŸŽ¯ D10 Model testing complete! This shows how well the model generalizes to unseen data!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-10T15:03:46.188887Z","iopub.execute_input":"2025-11-10T15:03:46.189205Z","iopub.status.idle":"2025-11-10T15:03:56.241299Z","shell.execute_reply.started":"2025-11-10T15:03:46.189189Z","shell.execute_reply":"2025-11-10T15:03:56.240765Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# # TEST WITH RANDOM IMAGES FROM VALIDATION SET\n# print(\"=== TESTING WITH 6 RANDOM IMAGES ===\")\n\n# import random\n# import matplotlib.pyplot as plt\n# import numpy as np\n\n# # Get 6 random indices from validation set\n# random_indices = random.sample(range(len(X_val)), 6)\n# print(f\"Testing on random samples: {random_indices}\")\n\n# # Show the random sequences and predictions with REAL IMAGES\n# fig, axes = plt.subplots(6, 6, figsize=(30, 25))\n\n# for row, idx in enumerate(random_indices):\n#     # Get the sequence and make prediction\n#     input_sequence = X_val[idx:idx+1]\n#     prediction = generator.predict(input_sequence, verbose=0)\n    \n#     # Get frames - these are the REAL images\n#     frame_1 = input_sequence[0, 0, :, :, 0]\n#     frame_2 = input_sequence[0, 1, :, :, 0]  \n#     frame_3 = input_sequence[0, 2, :, :, 0]\n#     last_frame = input_sequence[0, 3, :, :, 0]  # Last real input frame\n#     predicted_frame = prediction[0, :, :, 0]    # Model prediction\n#     actual_frame = y_val[idx, :, :, 0]          # Ground truth real frame\n    \n#     # Calculate regeneration areas\n#     pred_regeneration = np.abs(predicted_frame - last_frame)\n#     actual_regeneration = np.abs(actual_frame - last_frame)\n    \n#     # Calculate metrics\n#     pred_mask = (pred_regeneration > 0.15).astype(np.float32)\n#     actual_mask = (actual_regeneration > 0.15).astype(np.float32)\n#     overlap = np.sum(pred_mask * actual_mask)\n#     union = np.sum((pred_mask + actual_mask) > 0)\n#     iou = overlap / union if union > 0 else 0\n#     precision = overlap / np.sum(pred_mask) if np.sum(pred_mask) > 0 else 0\n#     recall = overlap / np.sum(actual_mask) if np.sum(actual_mask) > 0 else 0\n    \n#     # Show REAL input sequence\n#     axes[row, 0].imshow(frame_1, cmap='gray')\n#     axes[row, 0].set_title(f'Sample {idx}\\nReal Frame 1 (t-3)')\n#     axes[row, 0].axis('off')\n    \n#     axes[row, 1].imshow(frame_2, cmap='gray')\n#     axes[row, 1].set_title('Real Frame 2 (t-2)')\n#     axes[row, 1].axis('off')\n    \n#     axes[row, 2].imshow(frame_3, cmap='gray')\n#     axes[row, 2].set_title('Real Frame 3 (t-1)')\n#     axes[row, 2].axis('off')\n    \n#     # Show last REAL input frame\n#     axes[row, 3].imshow(last_frame, cmap='gray')\n#     axes[row, 3].set_title('Real Frame 4 (t=0)\\n(Last Input)')\n#     axes[row, 3].axis('off')\n    \n#     # Show MODEL PREDICTION (next frame)\n#     axes[row, 4].imshow(predicted_frame, cmap='gray')\n#     axes[row, 4].set_title(f'Model Prediction\\n(t+1)\\nIoU: {iou:.3f}')\n#     axes[row, 4].axis('off')\n    \n#     # Show ACTUAL REAL next frame (ground truth)\n#     axes[row, 5].imshow(actual_frame, cmap='gray')\n#     axes[row, 5].set_title('Actual Real Frame\\n(t+1 Ground Truth)')\n#     axes[row, 5].axis('off')\n\n# plt.tight_layout()\n# plt.show()\n\n# # COMPREHENSIVE COMPARISON: Real Images vs Predictions\n# print(\"\\n=== COMPREHENSIVE COMPARISON: REAL IMAGES vs PREDICTIONS ===\")\n# fig, axes = plt.subplots(6, 5, figsize=(25, 25))\n\n# for row, idx in enumerate(random_indices):\n#     input_sequence = X_val[idx:idx+1]\n#     prediction = generator.predict(input_sequence, verbose=0)\n    \n#     # Get REAL images\n#     last_real_frame = input_sequence[0, 3, :, :, 0]  # Last input (real)\n#     predicted_frame = prediction[0, :, :, 0]         # Model prediction\n#     actual_real_frame = y_val[idx, :, :, 0]          # Actual next frame (real)\n    \n#     # Calculate regeneration intensity\n#     pred_regeneration = np.abs(predicted_frame - last_real_frame)\n#     actual_regeneration = np.abs(actual_real_frame - last_real_frame)\n    \n#     # Calculate metrics\n#     pred_mask = (pred_regeneration > 0.15).astype(np.float32)\n#     actual_mask = (actual_regeneration > 0.15).astype(np.float32)\n#     overlap = np.sum(pred_mask * actual_mask)\n#     union = np.sum((pred_mask + actual_mask) > 0)\n#     iou = overlap / union if union > 0 else 0\n#     precision = overlap / np.sum(pred_mask) if np.sum(pred_mask) > 0 else 0\n#     recall = overlap / np.sum(actual_mask) if np.sum(actual_mask) > 0 else 0\n    \n#     # Column 1: Last Real Frame (baseline)\n#     axes[row, 0].imshow(last_real_frame, cmap='gray')\n#     axes[row, 0].set_title(f'Sample {idx}\\nLast Real Frame\\n(t=0 Baseline)')\n#     axes[row, 0].axis('off')\n    \n#     # Column 2: Predicted Next Frame\n#     axes[row, 1].imshow(predicted_frame, cmap='gray')\n#     axes[row, 1].set_title(f'Predicted Frame\\n(t+1)')\n#     axes[row, 1].axis('off')\n    \n#     # Column 3: Actual Real Next Frame\n#     axes[row, 2].imshow(actual_real_frame, cmap='gray')\n#     axes[row, 2].set_title('Actual Real Frame\\n(t+1 Ground Truth)')\n#     axes[row, 2].axis('off')\n    \n#     # Column 4: Regeneration Heatmaps Comparison\n#     # Create side-by-side heatmap\n#     heatmap_comparison = np.zeros((128, 256))\n#     heatmap_comparison[:, :128] = pred_regeneration\n#     heatmap_comparison[:, 128:] = actual_regeneration\n    \n#     im4 = axes[row, 3].imshow(heatmap_comparison, cmap='hot', vmin=0, vmax=1)\n#     axes[row, 3].set_title(f'Regeneration Heatmaps\\nLeft: Predicted, Right: Actual\\nIoU: {iou:.3f}')\n#     axes[row, 3].axis('off')\n#     plt.colorbar(im4, ax=axes[row, 3], fraction=0.046, pad=0.04)\n    \n#     # Column 5: Difference Map (Predicted vs Actual Real)\n#     difference = np.abs(predicted_frame - actual_real_frame)\n#     im5 = axes[row, 4].imshow(difference, cmap='coolwarm', vmin=0, vmax=1)\n#     axes[row, 4].set_title(f'Absolute Difference\\n(Predicted vs Actual Real)\\nAvg Diff: {np.mean(difference):.3f}')\n#     axes[row, 4].axis('off')\n#     plt.colorbar(im5, ax=axes[row, 4], fraction=0.046, pad=0.04)\n\n# plt.tight_layout()\n# plt.show()\n\n\n\n# # SIDE-BY-SIDE REAL COMPARISON GRID\n# print(\"\\n=== SIDE-BY-SIDE REAL IMAGE COMPARISON ===\")\n# fig, axes = plt.subplots(3, 4, figsize=(20, 15))\n\n# comparison_data = []\n# for i, idx in enumerate(random_indices[:6]):  # Compare first 6\n#     input_sequence = X_val[idx:ile dx+1]\n#     prediction = generator.predict(input_sequence, verbose=0)\n    \n#     last_real_frame = input_sequence[0, 3, :, :, 0]\n#     predicted_frame = prediction[0, :, :, 0]\n#     actual_real_frame = y_val[idx, :, :, 0]\n    \n#     # Calculate metrics\n#     pred_regeneration = np.abs(predicted_frame - last_real_frame)\n#     actual_regeneration = np.abs(actual_real_frame - last_real_frame)\n#     pred_mask = (pred_regeneration > 0.15).astype(np.float32)\n#     actual_mask = (actual_regeneration > 0.15).astype(np.float32)\n    \n#     overlap = np.sum(pred_mask * actual_mask)\n#     union = np.sum((pred_mask + actual_mask) > 0)\n#     iou = overlap / union if union > 0 else 0\n    \n#     # Row calculation\n#     row = i // 2\n#     col_start = (i % 2) * 2\n    \n#     # Left: Predicted\n#     axes[row, col_start].imshow(predicted_frame, cmap='gray')\n#     axes[row, col_start].set_title(f'Sample {idx}: Predicted\\nIoU: {iou:.3f}')\n#     axes[row, col_start].axis('off')\n    \n#     # Right: Actual Real\n#     axes[row, col_start + 1].imshow(actual_real_frame, cmap='gray')\n#     axes[row, col_start + 1].set_title(f'Sample {idx}: Actual Real')\n#     axes[row, col_start + 1].axis('off')\n    \n#     comparison_data.append({\n#         'sample': idx,\n#         'predicted_mean': np.mean(predicted_frame),\n#         'actual_mean': np.mean(actual_real_frame),\n#         'iou': iou\n#     })\n\n# plt.tight_layout()\n# plt.show()\n\n# # Print comprehensive metrics\n# print(\"\\n=== COMPREHENSIVE REAL IMAGE METRICS ===\")\n# random_ious = []\n# random_precisions = []\n# random_recalls = []\n# intensity_correlations = []\n\n# for idx in random_indices:\n#     input_sequence = X_val[idx:idx+1]\n#     prediction = generator.predict(input_sequence, verbose=0)\n    \n#     last_real_frame = input_sequence[0, 3, :, :, 0]\n#     predicted_frame = prediction[0, :, :, 0]\n#     actual_real_frame = y_val[idx, :, :, 0]\n    \n#     # Calculate regeneration\n#     pred_regeneration = np.abs(predicted_frame - last_real_frame)\n#     actual_regeneration = np.abs(actual_real_frame - last_real_frame)\n    \n#     # Binary masks for metrics\n#     pred_mask = (pred_regeneration > 0.15).astype(np.float32)\n#     actual_mask = (actual_regeneration > 0.15).astype(np.float32)\n    \n#     overlap = np.sum(pred_mask * actual_mask)\n#     union = np.sum((pred_mask + actual_mask) > 0)\n#     iou = overlap / union if union > 0 else 0\n#     precision = overlap / np.sum(pred_mask) if np.sum(pred_mask) > 0 else 0\n#     recall = overlap / np.sum(actual_mask) if np.sum(actual_mask) > 0 else 0\n    \n#     # Intensity correlation\n#     intensity_corr = np.corrcoef(predicted_frame.flatten(), actual_real_frame.flatten())[0, 1]\n    \n#     random_ious.append(iou)\n#     random_precisions.append(precision)\n#     random_recalls.append(recall)\n#     intensity_correlations.append(intensity_corr)\n    \n#     print(f\"Random Sample {idx}:\")\n#     print(f\"  IoU: {iou:.3f}\")\n#     print(f\"  Precision: {precision:.3f}\")\n#     print(f\"  Recall: {recall:.3f}\")\n#     print(f\"  Intensity Correlation: {intensity_corr:.3f}\")\n#     print(f\"  Predicted mean intensity: {np.mean(predicted_frame):.3f}\")\n#     print(f\"  Actual mean intensity: {np.mean(actual_real_frame):.3f}\")\n#     print(f\"  Predicted growth area: {np.sum(pred_mask):.0f} pixels\")\n#     print(f\"  Actual growth area: {np.sum(actual_mask):.0f} pixels\")\n#     print()\n\n# print(f\"\\nCOMPREHENSIVE SUMMARY - REAL IMAGE COMPARISON\")\n# print(f\"Average IoU: {np.mean(random_ious):.3f} Â± {np.std(random_ious):.3f}\")\n# print(f\"Average Precision: {np.mean(random_precisions):.3f} Â± {np.std(random_precisions):.3f}\")\n# print(f\"Average Recall: {np.mean(random_recalls):.3f} Â± {np.std(random_recalls):.3f}\")\n# print(f\"Average Intensity Correlation: {np.mean(intensity_correlations):.3f} Â± {np.std(intensity_correlations):.3f}\")\n\n# print(\"\\nREAL IMAGE COMPARISON COMPLETE!\")\n# print(\"Now you can visually compare ACTUAL real images with model predictions!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-10T16:24:52.121259Z","iopub.execute_input":"2025-11-10T16:24:52.121783Z","iopub.status.idle":"2025-11-10T16:24:52.128983Z","shell.execute_reply.started":"2025-11-10T16:24:52.121757Z","shell.execute_reply":"2025-11-10T16:24:52.128324Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# TEST WITH RANDOM IMAGES FROM VALIDATION SET\nprint(\"=== TESTING WITH 6 RANDOM IMAGES ===\")\n\nimport random\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# Get 6 random indices from validation set\nrandom_indices = random.sample(range(len(X_val)), 6)\nprint(f\"Testing on random samples: {random_indices}\")\n\n# Show the random sequences and predictions - KEEP NORMAL IMAGES\nfig, axes = plt.subplots(6, 5, figsize=(25, 25))\n\nfor row, idx in enumerate(random_indices):\n    # Get the sequence and make prediction\n    input_sequence = X_val[idx:idx+1]\n    prediction = generator.predict(input_sequence, verbose=0)\n    \n    # Get frames - KEEP AS NORMAL GRAYSCALE\n    frame_1 = input_sequence[0, 0, :, :, 0]\n    frame_2 = input_sequence[0, 1, :, :, 0]  \n    frame_3 = input_sequence[0, 2, :, :, 0]\n    last_frame = input_sequence[0, 3, :, :, 0]\n    predicted_frame = prediction[0, :, :, 0]  # Keep normal prediction\n    actual_frame = y_val[idx, :, :, 0]        # Keep normal actual\n    \n    # Calculate growth areas\n    pred_growth = np.abs(predicted_frame - last_frame)\n    actual_growth = np.abs(actual_frame - last_frame)\n    \n    # Calculate metrics\n    pred_mask = (pred_growth > 0.15).astype(np.float32)\n    actual_mask = (actual_growth > 0.15).astype(np.float32)\n    overlap = np.sum(pred_mask * actual_mask)\n    union = np.sum((pred_mask + actual_mask) > 0)\n    iou = overlap / union if union > 0 else 0\n    precision = overlap / np.sum(pred_mask) if np.sum(pred_mask) > 0 else 0\n    recall = overlap / np.sum(actual_mask) if np.sum(actual_mask) > 0 else 0\n    \n    # Show input sequence (first 3 frames) - NORMAL GRAYSCALE\n    axes[row, 0].imshow(frame_1, cmap='gray')\n    axes[row, 0].set_title(f'Random Sample {idx}\\nFrame 1')\n    axes[row, 0].axis('off')\n    \n    axes[row, 1].imshow(frame_2, cmap='gray')\n    axes[row, 1].set_title('Frame 2')\n    axes[row, 1].axis('off')\n    \n    axes[row, 2].imshow(frame_3, cmap='gray')\n    axes[row, 2].set_title('Frame 3')\n    axes[row, 2].axis('off')\n    \n    # Show last input frame - NORMAL GRAYSCALE\n    axes[row, 3].imshow(last_frame, cmap='gray')\n    axes[row, 3].set_title('Frame 4 (Last Input)')\n    axes[row, 3].axis('off')\n    \n    # Show prediction - NORMAL GRAYSCALE\n    axes[row, 4].imshow(predicted_frame, cmap='gray')\n    axes[row, 4].set_title(f'Predicted\\nIoU: {iou:.3f}')\n    axes[row, 4].axis('off')\n\nplt.tight_layout()\nplt.show()\n\n# NORMAL IMAGES + RGB OVERLAP ANALYSIS\nprint(\"\\n=== NORMAL IMAGES WITH RGB OVERLAP ANALYSIS ===\")\nfig, axes = plt.subplots(6, 4, figsize=(20, 25))\n\nfor row, idx in enumerate(random_indices):\n    input_sequence = X_val[idx:idx+1]\n    prediction = generator.predict(input_sequence, verbose=0)\n    \n    last_frame = input_sequence[0, 3, :, :, 0]\n    predicted_frame = prediction[0, :, :, 0]  # Normal prediction\n    actual_frame = y_val[idx, :, :, 0]        # Normal actual\n    \n    # Calculate growth intensity (difference from last frame)\n    pred_growth = np.abs(predicted_frame - last_frame)\n    actual_growth = np.abs(actual_frame - last_frame)\n    \n    # Calculate metrics\n    pred_mask = (pred_growth > 0.15).astype(np.float32)\n    actual_mask = (actual_growth > 0.15).astype(np.float32)\n    overlap = np.sum(pred_mask * actual_mask)\n    union = np.sum((pred_mask + actual_mask) > 0)\n    iou = overlap / union if union > 0 else 0\n    precision = overlap / np.sum(pred_mask) if np.sum(pred_mask) > 0 else 0\n    recall = overlap / np.sum(actual_mask) if np.sum(actual_mask) > 0 else 0\n    \n    # Column 1: Normal Predicted Frame\n    axes[row, 0].imshow(predicted_frame, cmap='gray')\n    axes[row, 0].set_title(f'Sample {idx}\\nPredicted Frame\\n(Normal)')\n    axes[row, 0].axis('off')\n    \n    # Column 2: Normal Actual Frame\n    axes[row, 1].imshow(actual_frame, cmap='gray')\n    axes[row, 1].set_title(f'Actual Frame\\n(Normal)\\nIoU: {iou:.3f}')\n    axes[row, 1].axis('off')\n    \n    # Column 3: Side-by-side normal comparison\n    side_by_side = np.zeros((128, 256))  # Create side-by-side grayscale\n    side_by_side[:, :128] = predicted_frame  # Left: predicted\n    side_by_side[:, 128:] = actual_frame     # Right: actual\n    \n    axes[row, 2].imshow(side_by_side, cmap='gray')\n    axes[row, 2].set_title(f'Comparison\\nLeft: Predicted, Right: Actual')\n    axes[row, 2].axis('off')\n    \n    # Column 4: RGB OVERLAP ANALYSIS (Green, Red, Blue only)\n    rgb_overlap = np.ones((128, 128, 3))  # White background\n    \n    pred_binary = pred_growth > 0.15\n    actual_binary = actual_growth > 0.15\n    \n    # GREEN = True Positive (both predicted and actual)\n    rgb_overlap[pred_binary & actual_binary] = [0.0, 1.0, 0.0]  # Green\n    \n    # RED = False Positive (predicted but not actual)\n    rgb_overlap[pred_binary & ~actual_binary] = [1.0, 0.0, 0.0]  # Red\n    \n    # BLUE = False Negative (actual but not predicted)\n    rgb_overlap[~pred_binary & actual_binary] = [0.0, 0.0, 1.0]  # Blue\n    \n    axes[row, 3].imshow(rgb_overlap)\n    axes[row, 3].set_title(f'RGB Overlap Analysis\\n(G=TP, R=FP, B=FN)\\nPrecision: {precision:.3f}, Recall: {recall:.3f}')\n    axes[row, 3].axis('off')\n\nplt.tight_layout()\nplt.show()\n\n# PURE RGB OVERLAP GRID\nprint(\"\\n=== PURE RGB OVERLAP GRID ===\")\nfig, axes = plt.subplots(2, 3, figsize=(18, 12))\n\nfor i, idx in enumerate(random_indices[:6]):\n    input_sequence = X_val[idx:idx+1]\n    prediction = generator.predict(input_sequence, verbose=0)\n    \n    last_frame = input_sequence[0, 3, :, :, 0]\n    predicted_frame = prediction[0, :, :, 0]\n    actual_frame = y_val[idx, :, :, 0]\n    \n    # Calculate growth\n    pred_growth = np.abs(predicted_frame - last_frame)\n    actual_growth = np.abs(actual_frame - last_frame)\n    \n    # Binary masks\n    pred_mask = pred_growth > 0.15\n    actual_mask = actual_growth > 0.15\n    \n    # Calculate IoU\n    overlap = np.sum(pred_mask & actual_mask)\n    union = np.sum(pred_mask | actual_mask)\n    iou = overlap / union if union > 0 else 0\n    \n    row = i // 3\n    col = i % 3\n    \n    # Create RGB overlap visualization\n    rgb_display = np.ones((128, 128, 3))  # White background\n    \n    # GREEN = True Positives\n    rgb_display[pred_mask & actual_mask] = [0.0, 1.0, 0.0]  # Green\n    # RED = False Positives\n    rgb_display[pred_mask & ~actual_mask] = [1.0, 0.0, 0.0]  # Red\n    # BLUE = False Negatives\n    rgb_display[~pred_mask & actual_mask] = [0.0, 0.0, 1.0]  # Blue\n    \n    axes[row, col].imshow(rgb_display)\n    axes[row, col].set_title(f'Sample {idx}\\nIoU: {iou:.3f}\\n(G=Correct, R=Over, B=Under)')\n    axes[row, col].axis('off')\n\nplt.tight_layout()\nplt.show()\n\n# COMPREHENSIVE COMPARISON: NORMAL IMAGES + RGB OVERLAP\nprint(\"\\n=== COMPREHENSIVE COMPARISON: NORMAL IMAGES + RGB OVERLAP ===\")\nfig, axes = plt.subplots(6, 3, figsize=(15, 25))\n\nfor row, idx in enumerate(random_indices):\n    input_sequence = X_val[idx:idx+1]\n    prediction = generator.predict(input_sequence, verbose=0)\n    \n    last_frame = input_sequence[0, 3, :, :, 0]\n    predicted_frame = prediction[0, :, :, 0]  # Normal\n    actual_frame = y_val[idx, :, :, 0]        # Normal\n    \n    # Calculate growth\n    pred_growth = np.abs(predicted_frame - last_frame)\n    actual_growth = np.abs(actual_frame - last_frame)\n    \n    # Binary masks\n    pred_mask = pred_growth > 0.15\n    actual_mask = actual_growth > 0.15\n    \n    # Calculate metrics\n    overlap = np.sum(pred_mask & actual_mask)\n    union = np.sum(pred_mask | actual_mask)\n    iou = overlap / union if union > 0 else 0\n    precision = overlap / np.sum(pred_mask) if np.sum(pred_mask) > 0 else 0\n    recall = overlap / np.sum(actual_mask) if np.sum(actual_mask) > 0 else 0\n    \n    # Column 1: Normal Predicted Frame\n    axes[row, 0].imshow(predicted_frame, cmap='gray')\n    axes[row, 0].set_title(f'Sample {idx}\\nNormal Predicted')\n    axes[row, 0].axis('off')\n    \n    # Column 2: Normal Actual Frame\n    axes[row, 1].imshow(actual_frame, cmap='gray')\n    axes[row, 1].set_title(f'Normal Actual\\nIoU: {iou:.3f}')\n    axes[row, 1].axis('off')\n    \n    # Column 3: RGB Overlap Analysis\n    rgb_overlap = np.ones((128, 128, 3))  # White background\n    \n    # GREEN = True Positives\n    rgb_overlap[pred_mask & actual_mask] = [0.0, 1.0, 0.0]  # Green\n    # RED = False Positives\n    rgb_overlap[pred_mask & ~actual_mask] = [1.0, 0.0, 0.0]  # Red\n    # BLUE = False Negatives\n    rgb_overlap[~pred_mask & actual_mask] = [0.0, 0.0, 1.0]  # Blue\n    \n    axes[row, 2].imshow(rgb_overlap)\n    axes[row, 2].set_title(f'RGB Overlap\\n(G=Both, R=Over, B=Under)\\nP: {precision:.3f}, R: {recall:.3f}')\n    axes[row, 2].axis('off')\n\nplt.tight_layout()\nplt.show()\n\n# FINAL CLEAN VISUALIZATION\nprint(\"\\n=== FINAL CLEAN VISUALIZATION ===\")\nfig, axes = plt.subplots(3, 4, figsize=(20, 15))\n\nfor i, idx in enumerate(random_indices[:6]):\n    input_sequence = X_val[idx:idx+1]\n    prediction = generator.predict(input_sequence, verbose=0)\n    \n    last_frame = input_sequence[0, 3, :, :, 0]\n    predicted_frame = prediction[0, :, :, 0]\n    actual_frame = y_val[idx, :, :, 0]\n    \n    # Calculate growth\n    pred_growth = np.abs(predicted_frame - last_frame)\n    actual_growth = np.abs(actual_frame - last_frame)\n    \n    # Binary masks\n    pred_mask = pred_growth > 0.15\n    actual_mask = actual_growth > 0.15\n    \n    # Calculate IoU\n    overlap = np.sum(pred_mask & actual_mask)\n    union = np.sum(pred_mask | actual_mask)\n    iou = overlap / union if union > 0 else 0\n    \n    row = i // 2\n    col_start = (i % 2) * 2\n    \n    # Left: Normal Predicted\n    axes[row, col_start].imshow(predicted_frame, cmap='gray')\n    axes[row, col_start].set_title(f'Sample {idx}: Predicted\\n(Normal Image)')\n    axes[row, col_start].axis('off')\n    \n    # Right: Normal Actual\n    axes[row, col_start + 1].imshow(actual_frame, cmap='gray')\n    axes[row, col_start + 1].set_title(f'Sample {idx}: Actual\\nIoU: {iou:.3f}')\n    axes[row, col_start + 1].axis('off')\n\nplt.tight_layout()\nplt.show()\n\n# Print detailed metrics\nprint(\"\\n=== DETAILED METRICS FOR RANDOM SAMPLES ===\")\nrandom_ious = []\nrandom_precisions = []\nrandom_recalls = []\n\nfor idx in random_indices:\n    input_sequence = X_val[idx:idx+1]\n    prediction = generator.predict(input_sequence, verbose=0)\n    \n    last_frame = input_sequence[0, 3, :, :, 0]\n    predicted_frame = prediction[0, :, :, 0]\n    actual_frame = y_val[idx, :, :, 0]\n    \n    pred_growth = np.abs(predicted_frame - last_frame)\n    actual_growth = np.abs(actual_frame - last_frame)\n    \n    pred_mask = (pred_growth > 0.15).astype(np.float32)\n    actual_mask = (actual_growth > 0.15).astype(np.float32)\n    \n    overlap = np.sum(pred_mask * actual_mask)\n    union = np.sum((pred_mask + actual_mask) > 0)\n    iou = overlap / union if union > 0 else 0\n    precision = overlap / np.sum(pred_mask) if np.sum(pred_mask) > 0 else 0\n    recall = overlap / np.sum(actual_mask) if np.sum(actual_mask) > 0 else 0\n    \n    random_ious.append(iou)\n    random_precisions.append(precision)\n    random_recalls.append(recall)\n    \n    print(f\"Random Sample {idx}:\")\n    print(f\"  IoU: {iou:.3f}\")\n    print(f\"  Precision: {precision:.3f}\")\n    print(f\"  Recall: {recall:.3f}\")\n    print(f\"  Predicted growth area: {np.sum(pred_mask):.0f} pixels\")\n    print(f\"  Actual growth area: {np.sum(actual_mask):.0f} pixels\")\n    print(f\"  Growth ratio: {np.sum(pred_mask)/np.sum(actual_mask):.2f}\" if np.sum(actual_mask) > 0 else \"  Growth ratio: N/A\")\n    print()\n\nprint(f\"\\nðŸ“Š RANDOM SAMPLE SUMMARY\")\nprint(f\"Average IoU: {np.mean(random_ious):.3f} Â± {np.std(random_ious):.3f}\")\nprint(f\"Average Precision: {np.mean(random_precisions):.3f} Â± {np.std(random_precisions):.3f}\")\nprint(f\"Average Recall: {np.mean(random_recalls):.3f} Â± {np.std(random_recalls):.3f}\")\n\nprint(\"\\nðŸŽ¯ NORMAL IMAGES + RGB OVERLAP COMPLETE!\")\nprint(\"Predicted and actual frames shown as normal grayscale images!\")\nprint(\"RGB overlap analysis shows:Green=Correct,  Red=Over-prediction,  Blue=Under-prediction\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-10T15:06:03.219882Z","iopub.execute_input":"2025-11-10T15:06:03.220510Z","iopub.status.idle":"2025-11-10T15:06:14.788922Z","shell.execute_reply.started":"2025-11-10T15:06:03.220486Z","shell.execute_reply":"2025-11-10T15:06:14.788338Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# TEST WITH RANDOM IMAGES FROM VALIDATION SET\nprint(\"=== TESTING WITH 6 RANDOM IMAGES ===\")\n\nimport random\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# Get 6 random indices from validation set\nrandom_indices = random.sample(range(len(X_val)), 6)\nprint(f\"Testing on random samples: {random_indices}\")\n\n# Show the random sequences and predictions\nfig, axes = plt.subplots(6, 5, figsize=(25, 25))\n\nfor row, idx in enumerate(random_indices):\n    # Get the sequence and make prediction\n    input_sequence = X_val[idx:idx+1]\n    prediction = generator.predict(input_sequence, verbose=0)\n    \n    # Get frames\n    frame_1 = input_sequence[0, 0, :, :, 0]\n    frame_2 = input_sequence[0, 1, :, :, 0]  \n    frame_3 = input_sequence[0, 2, :, :, 0]\n    last_frame = input_sequence[0, 3, :, :, 0]\n    predicted_frame = prediction[0, :, :, 0]\n    actual_frame = y_val[idx, :, :, 0]\n    \n    # Calculate growth areas\n    pred_growth = np.abs(predicted_frame - last_frame)\n    actual_growth = np.abs(actual_frame - last_frame)\n    \n    # Calculate metrics\n    pred_mask = (pred_growth > 0.15).astype(np.float32)\n    actual_mask = (actual_growth > 0.15).astype(np.float32)\n    overlap = np.sum(pred_mask * actual_mask)\n    union = np.sum((pred_mask + actual_mask) > 0)\n    iou = overlap / union if union > 0 else 0\n    precision = overlap / np.sum(pred_mask) if np.sum(pred_mask) > 0 else 0\n    recall = overlap / np.sum(actual_mask) if np.sum(actual_mask) > 0 else 0\n    \n    # Show input sequence (first 3 frames)\n    axes[row, 0].imshow(frame_1, cmap='gray')\n    axes[row, 0].set_title(f'Random Sample {idx}\\nFrame 1')\n    axes[row, 0].axis('off')\n    \n    axes[row, 1].imshow(frame_2, cmap='gray')\n    axes[row, 1].set_title('Frame 2')\n    axes[row, 1].axis('off')\n    \n    axes[row, 2].imshow(frame_3, cmap='gray')\n    axes[row, 2].set_title('Frame 3')\n    axes[row, 2].axis('off')\n    \n    # Show last input frame\n    axes[row, 3].imshow(last_frame, cmap='gray')\n    axes[row, 3].set_title('Frame 4 (Last Input)')\n    axes[row, 3].axis('off')\n    \n    # Show prediction\n    axes[row, 4].imshow(predicted_frame, cmap='gray')\n    axes[row, 4].set_title(f'Predicted\\nIoU: {iou:.3f}')\n    axes[row, 4].axis('off')\n\nplt.tight_layout()\nplt.show()\n\n\n# GRADUAL INTENSITY - DARKER GRAY FOR STRONGER growth\nprint(\"\\n=== GRADUAL INTENSITY HEATMAPS (Black/Gray on White) ===\")\nfig, axes = plt.subplots(6, 3, figsize=(18, 25))\n\nfor row, idx in enumerate(random_indices):\n    input_sequence = X_val[idx:idx+1]\n    prediction = generator.predict(input_sequence, verbose=0)\n    \n    last_frame = input_sequence[0, 3, :, :, 0]\n    predicted_frame = prediction[0, :, :, 0]\n    actual_frame = y_val[idx, :, :, 0]\n    \n    # Calculate growth intensity\n    pred_growth = np.abs(predicted_frame - last_frame)\n    actual_growth = np.abs(actual_frame - last_frame)\n    \n    # Calculate metrics\n    pred_mask = (pred_growth > 0.15).astype(np.float32)\n    actual_mask = (actual_growth > 0.15).astype(np.float32)\n    overlap = np.sum(pred_mask * actual_mask)\n    union = np.sum((pred_mask + actual_mask) > 0)\n    iou = overlap / union if union > 0 else 0\n    \n    # Column 1: Predicted with gradual black intensity\n    pred_gradual = np.ones((128, 128, 3))  # White background\n    # Normalize growth intensity to [0, 1] and invert (darker = stronger)\n    pred_normalized = 1 - np.clip(pred_growth, 0, 1)  # Invert so darker = more growth\n    # Apply to all channels for grayscale\n    pred_gradual[:, :, 0] = pred_normalized  # Red channel\n    pred_gradual[:, :, 1] = pred_normalized  # Green channel\n    pred_gradual[:, :, 2] = pred_normalized  # Blue channel\n    \n    axes[row, 0].imshow(pred_gradual)\n    axes[row, 0].set_title(f'Sample {idx}\\nPredicted Growth\\n(Darker = Stronger Growth)')\n    axes[row, 0].axis('off')\n    \n    # Column 2: Actual with gradual black intensity\n    actual_gradual = np.ones((128, 128, 3))  # White background\n    actual_normalized = 1 - np.clip(actual_growth, 0, 1)  # Invert\n    actual_gradual[:, :, 0] = actual_normalized\n    actual_gradual[:, :, 1] = actual_normalized\n    actual_gradual[:, :, 2] = actual_normalized\n    \n    axes[row, 1].imshow(actual_gradual)\n    axes[row, 1].set_title(f'Actual Growth\\n(Darker = Stronger Growth)\\nIoU: {iou:.3f}')\n    axes[row, 1].axis('off')\n    \n    # Column 3: Difference map (Black = match, Dark Gray = over, Light Gray = under)\n    diff_map = np.ones((128, 128, 3))  # White background\n    pred_normalized = np.clip(pred_growth, 0, 1)\n    actual_normalized = np.clip(actual_growth, 0, 1)\n    \n    # Areas where both have growth - Black\n    both_growth = (pred_normalized > 0.15) & (actual_normalized > 0.15)\n    diff_map[both_growth] = [0.0, 0.0, 0.0]  # Black\n    \n    # Areas where only predicted has growth - Dark Gray (over-prediction)\n    over_pred = (pred_normalized > 0.15) & (actual_normalized <= 0.15)\n    diff_map[over_pred] = [0.3, 0.3, 0.3]  # Dark Gray\n    \n    # Areas where only actual has growth - Light Gray (under-prediction)\n    under_pred = (pred_normalized <= 0.15) & (actual_normalized > 0.15)\n    diff_map[under_pred] = [0.7, 0.7, 0.7]  # Light Gray\n    \n    axes[row, 2].imshow(diff_map)\n    axes[row, 2].set_title(f'Prediction Accuracy\\n(B=Correct, DG=Over, LG=Under)')\n    axes[row, 2].axis('off')\n\nplt.tight_layout()\nplt.show()\n\n\n# Print detailed metrics\nprint(\"\\n=== DETAILED METRICS FOR RANDOM SAMPLES ===\")\nrandom_ious = []\nrandom_precisions = []\nrandom_recalls = []\n\nfor idx in random_indices:\n    input_sequence = X_val[idx:idx+1]\n    prediction = generator.predict(input_sequence, verbose=0)\n    \n    last_frame = input_sequence[0, 3, :, :, 0]\n    predicted_frame = prediction[0, :, :, 0]\n    actual_frame = y_val[idx, :, :, 0]\n    \n    pred_growth = np.abs(predicted_frame - last_frame)\n    actual_growth = np.abs(actual_frame - last_frame)\n    \n    pred_mask = (pred_growth > 0.15).astype(np.float32)\n    actual_mask = (actual_growth > 0.15).astype(np.float32)\n    \n    overlap = np.sum(pred_mask * actual_mask)\n    union = np.sum((pred_mask + actual_mask) > 0)\n    iou = overlap / union if union > 0 else 0\n    precision = overlap / np.sum(pred_mask) if np.sum(pred_mask) > 0 else 0\n    recall = overlap / np.sum(actual_mask) if np.sum(actual_mask) > 0 else 0\n    \n    random_ious.append(iou)\n    random_precisions.append(precision)\n    random_recalls.append(recall)\n    \n    print(f\"Random Sample {idx}:\")\n    print(f\"  IoU: {iou:.3f}\")\n    print(f\"  Precision: {precision:.3f}\")\n    print(f\"  Recall: {recall:.3f}\")\n    print(f\"  Predicted growth area: {np.sum(pred_mask):.0f} pixels\")\n    print(f\"  Actual growth area: {np.sum(actual_mask):.0f} pixels\")\n    print(f\"  Growth ratio: {np.sum(pred_mask)/np.sum(actual_mask):.2f}\" if np.sum(actual_mask) > 0 else \"  Growth ratio: N/A\")\n    print()\n\nprint(f\"\\nðŸ“Š RANDOM SAMPLE SUMMARY\")\nprint(f\"Average IoU: {np.mean(random_ious):.3f} Â± {np.std(random_ious):.3f}\")\nprint(f\"Average Precision: {np.mean(random_precisions):.3f} Â± {np.std(random_precisions):.3f}\")\nprint(f\"Average Recall: {np.mean(random_recalls):.3f} Â± {np.std(random_recalls):.3f}\")\n\nprint(\"\\nðŸŽ¯ WHITE BACKGROUND HEATMAPS COMPLETE!\")\nprint(\"Black highlights on white background clearly show growth areas!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-10T15:06:52.690742Z","iopub.execute_input":"2025-11-10T15:06:52.691026Z","iopub.status.idle":"2025-11-10T15:07:00.755785Z","shell.execute_reply.started":"2025-11-10T15:06:52.691006Z","shell.execute_reply":"2025-11-10T15:07:00.755013Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Compare: **First Input Frame** vs **Predicted Next Frame**\n\nprint(\"=== FIRST INPUT FRAME vs PREDICTED NEXT FRAME ===\")\nfig, axes = plt.subplots(6, 3, figsize=(18, 25))\n\nfor row, idx in enumerate(random_indices):\n    seq = X_val[idx:idx+1]\n    pred = generator.predict(seq, verbose=0)\n    \n    frame_1 = seq[0, 0, :, :, 0]           # First frame in sequence (t=0)\n    last_frame = seq[0, 3, :, :, 0]         # Last input frame (t=3)\n    pred_frame = pred[0, :, :, 0]           # Predicted next (t=4)\n    actual_frame = y_val[idx, :, :, 0]      # True next (t=4)\n\n    # Column 1: First Input Frame\n    axes[row, 0].imshow(frame_1, cmap='gray')\n    axes[row, 0].set_title(f'Sample {idx} - Frame 1 (First Input)')\n    axes[row, 0].axis('off')\n\n    # Column 2: Predicted Next Frame\n    axes[row, 1].imshow(pred_frame, cmap='gray')\n    axes[row, 1].set_title(f'Predicted Frame 5\\n(from 4-frame input)')\n    axes[row, 1].axis('off')\n\n    # Column 3: Growth Overlay on First Frame\n    growth = np.abs(pred_frame - frame_1)\n    overlay = frame_1.copy()\n    mask = growth > 0.15\n    overlay[mask] = np.clip(overlay[mask] - 0.5, 0, 1)  # Darken growth areas\n    axes[row, 2].imshow(overlay, cmap='gray')\n    axes[row, 2].set_title(f'Frame 1 + Predicted Growth\\n(Darker = new cell mass)')\n    axes[row, 2].axis('off')\n\nplt.tight_layout()\nplt.show()\n\nprint(\"Model predicts growth **from initial cell positions** in Frame 1!\")\nprint(\"Matches LiveCell paper (Fig 3): growth radiates from t=0 structures.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-10T15:07:10.897383Z","iopub.execute_input":"2025-11-10T15:07:10.897984Z","iopub.status.idle":"2025-11-10T15:07:13.431130Z","shell.execute_reply.started":"2025-11-10T15:07:10.897960Z","shell.execute_reply":"2025-11-10T15:07:13.430214Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"\n\n---\n\n###  Side-Wise Predictive Power Analysis\n\n**Objective:**\nTo evaluate whether **right-side image regions** contribute more to model prediction accuracy compared to the **left side**.\n\n---\n\n### Methodology\n\n* **Full Prediction:** Model predicts the next frame using the complete input.\n* **Right-Side Only:** Left half (columns 0â€“63) is zeroed out â†’ prediction from right features only.\n* **Left-Side Only:** Right half (columns 64â€“127) is zeroed out â†’ prediction from left features only.\n* **Error Metric:** Mean Absolute Error (MAE) between predicted and actual target frame.\n\n---\n\n###  Metrics\n\n| Metric                    | Description                                                                 |\n| :------------------------ | :-------------------------------------------------------------------------- |\n| **MAE**                   | Measures average pixel-level deviation between prediction and ground truth. |\n| **Texture Strength**      | Mean gradient magnitude, indicates edge richness and local detail.          |\n| **Variation (Std. Dev.)** | Reflects contrast or dynamic range of pixel intensities.                    |\n| **Mean Intensity**        | Average pixel brightness, showing signal strength.                          |\n\n---\n\n### Key Analysis\n\n* Compare **MAE** for left-only vs right-only inputs across multiple samples.\n* Compute **feature ratios** (Right/Left) for:\n\n  * Intensity\n  * Texture\n  * Variation\n* Evaluate **importance mask correlation** between modelâ€™s attention map and spatial regions.\n\n---\n\n### Interpretation\n\n* If **Right-side MAE < Left-side MAE**, the right features are **more predictive**.\n* A higher **texture and importance ratio** on the right suggests **stronger spatial cues** influencing predictions.\n* This test validates whether **asymmetry in visual input** impacts learning effectiveness.\n\n---\n\n","metadata":{}},{"cell_type":"code","source":"# # === ANALYZE WHY: RIGHT vs LEFT FEATURE DIFFERENCES ===\n# print(\"\\nANALYZING RIGHT vs LEFT FEATURES\")\n\n# def analyze_side_differences(sample_input, importance_mask):\n#     frame1 = sample_input[0, 0, :, :, 0]  # Frame 1 (most important)\n\n#     H, W = frame1.shape\n#     mid = W // 2  # 64 if 128px\n\n#     left_region = frame1[:, :mid]\n#     right_region = frame1[:, mid:]\n\n#     # Texture metrics\n#     def get_texture_stats(region):\n#         if region.size == 0 or np.all(region == 0):\n#             return 0.0, 0.0, 0.0\n#         grad_x = np.abs(np.diff(region, axis=1))\n#         grad_y = np.abs(np.diff(region, axis=0))\n#         texture = np.mean(np.concatenate([grad_x, grad_y]))\n#         variation = np.std(region)\n#         intensity = np.mean(region)\n#         return texture, variation, intensity\n\n#     l_tex, l_var, l_int = get_texture_stats(left_region)\n#     r_tex, r_var, r_int = get_texture_stats(right_region)\n\n#     # Importance from heatmap\n#     l_imp = np.mean(importance_mask[:, :mid])\n#     r_imp = np.mean(importance_mask[:, mid:])\n\n#     print(f\"\\nFRAME 1: LEFT vs RIGHT\")\n#     print(f\"{'Metric':<12} {'Left':<8} {'Right':<8} {'R/L Ratio'}\")\n#     print(f\"{'Intensity':<12} {l_int:<8.4f} {r_int:<8.4f} {r_int/l_int if l_int>0 else 0:.2f}x\")\n#     print(f\"{'Texture':<12} {l_tex:<8.4f} {r_tex:<8.4f} {r_tex/l_tex if l_tex>0 else 0:.2f}x\")\n#     print(f\"{'Variation':<12} {l_var:<8.4f} {r_var:<8.4f} {r_var/l_var if l_var>0 else 0:.2f}x\")\n#     print(f\"{'Importance':<12} {l_imp:<8.3f} {r_imp:<8.3f} {r_imp/l_imp if l_imp>0 else 0:.2f}x\")\n\n#     # Visual\n#     fig, ax = plt.subplots(1, 3, figsize=(12, 4))\n#     ax[0].imshow(frame1, cmap='gray')\n#     ax[0].axvline(mid, color='yellow', linestyle='--')\n#     ax[0].set_title(\"Frame 1 (Split)\")\n#     ax[1].imshow(left_region, cmap='gray')\n#     ax[1].set_title(\"Left Half\")\n#     ax[2].imshow(right_region, cmap='gray')\n#     ax[2].set_title(\"Right Half\")\n#     plt.tight_layout()\n#     plt.show()\n\n# # Run analysis\n# sample_input = X_val[0:1]  # First validation sample\n# analyze_side_differences(sample_input, overall_heatmap_2d)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-10T15:26:05.409089Z","iopub.execute_input":"2025-11-10T15:26:05.409334Z","iopub.status.idle":"2025-11-10T15:26:05.413751Z","shell.execute_reply.started":"2025-11-10T15:26:05.409316Z","shell.execute_reply":"2025-11-10T15:26:05.413063Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# # TEST IF RIGHT-SIDE FEATURES ARE MORE PREDICTIVE\n# print(\"=== TESTING RIGHT-SIDE PREDICTIVE POWER ===\")\n\n# def test_side_predictive_power(generator, X_data, y_data, num_samples=10):\n#     \"\"\"Test if right-side features are actually more predictive\"\"\"\n    \n#     right_side_errors = []\n#     left_side_errors = []\n#     # \n#     for i in range(min(num_samples, len(X_data))):\n#         # Full prediction\n#         full_input = X_data[i:i+1]\n#         full_pred = generator.predict(full_input, verbose=0)[0, :, :, 0]\n#         actual = y_data[i, :, :, 0]\n        \n#         # Right-side only prediction (zero out left)\n#         right_input = full_input.copy()\n#         right_input[0, :, :, :64, :] = 0  # Zero left side\n#         right_pred = generator.predict(right_input, verbose=0)[0, :, :, 0]\n#         right_error = np.mean(np.abs(right_pred - actual))\n        \n#         # Left-side only prediction (zero out right)  \n#         left_input = full_input.copy()\n#         left_input[0, :, :, 64:, :] = 0  # Zero right side\n#         left_pred = generator.predict(left_input, verbose=0)[0, :, :, 0]\n#         left_error = np.mean(np.abs(left_pred - actual))\n        \n#         right_side_errors.append(right_error)\n#         left_side_errors.append(left_error)\n        \n#         print(f\"Sample {i}: Right-only error: {right_error:.4f}, Left-only error: {left_error:.4f}\")\n    \n#     avg_right_error = np.mean(right_side_errors)\n#     avg_left_error = np.mean(left_side_errors)\n    \n#     print(f\"\\n AVERAGE ERRORS:\")\n#     print(f\"Using only RIGHT side: {avg_right_error:.4f} MAE\")\n#     print(f\"Using only LEFT side:  {avg_left_error:.4f} MAE\")\n    \n#     if avg_right_error < avg_left_error:\n#         improvement = ((avg_left_error - avg_right_error) / avg_left_error) * 100\n#         print(f\" RIGHT side is {improvement:.1f}% more predictive!\")\n#     else:\n#         print(\" Left side appears more predictive (unexpected)\")\n    \n#     return avg_right_error, avg_left_error\n\n# # Run the test\n# print(\"Testing predictive power of each side...\")\n# right_error, left_error = test_side_predictive_power(generator, X_val[:10], y_val[:10])\n\n# # VISUALIZE WHAT THE MODEL SEES DIFFERENTLY\n# print(\"\\nðŸ” ANALYZING RIGHT vs LEFT FEATURE DIFFERENCES\")\n\n# def analyze_side_differences(sample_input, importance_mask):\n#     \"\"\"What features differ between right and left sides?\"\"\"\n    \n#     frame1 = sample_input[0, 0, :, :, 0]  # Most important frame\n    \n#     # Analyze texture differences\n#     def analyze_texture(region):\n#         if np.sum(region) == 0:\n#             return 0, 0, 0\n#         # Simple texture metrics\n#         gradient_x = np.abs(np.gradient(region, axis=1))\n#         gradient_y = np.abs(np.gradient(region, axis=0))\n#         texture_strength = np.mean(gradient_x + gradient_y)\n#         variation = np.std(region)\n#         return texture_strength, variation, np.mean(region)\n    \n#     left_region = frame1[:, :64]\n#     right_region = frame1[:, 64:]\n    \n#     left_texture, left_variation, left_mean = analyze_texture(left_region)\n#     right_texture, right_variation, right_mean = analyze_texture(right_region)\n    \n#     print(f\"\\n FEATURE COMPARISON (Frame 1):\")\n#     print(f\"               LEFT       RIGHT     Ratio\")\n#     print(f\"Intensity:    {left_mean:.4f}    {right_mean:.4f}    {right_mean/left_mean:.2f}x\")\n#     print(f\"Texture:      {left_texture:.4f}    {right_texture:.4f}    {right_texture/left_texture:.2f}x\")\n#     print(f\"Variation:    {left_variation:.4f}    {right_variation:.4f}    {right_variation/left_variation:.2f}x\")\n    \n#     # Check importance correlation\n#     left_importance = np.mean(importance_mask[:, :64])\n#     right_importance = np.mean(importance_mask[:, 64:])\n    \n#     print(f\"\\n IMPORTANCE CORRELATION:\")\n#     print(f\"Left side importance:  {left_importance:.3f}\")\n#     print(f\"Right side importance: {right_importance:.3f}\")\n#     print(f\"Right/Left importance ratio: {right_importance/left_importance:.2f}x\")\n\n# analyze_side_differences(sample_input, overall_heatmap_2d)\n\n# #","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-10T15:26:25.774345Z","iopub.execute_input":"2025-11-10T15:26:25.774609Z","iopub.status.idle":"2025-11-10T15:26:25.779867Z","shell.execute_reply.started":"2025-11-10T15:26:25.774588Z","shell.execute_reply":"2025-11-10T15:26:25.779097Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport numpy as np\nimport random\n\n# === PICK 6 RANDOM SAMPLES ===\nrandom_indices = random.sample(range(len(X_val)), 6)\nprint(\"=== GRADUAL INTENSITY HEATMAPS: PREDICTED vs ACTUAL (Darker = Stronger Growth) ===\")\n\nfig, axes = plt.subplots(6, 3, figsize=(18, 25))\n\nfor row, idx in enumerate(random_indices):\n    seq = X_val[idx:idx+1]\n    pred = generator.predict(seq, verbose=0)\n    \n    last_frame = seq[0, 3, :, :, 0]           # Frame 4\n    pred_frame = pred[0, :, :, 0]             # Predicted\n    actual_frame = y_val[idx, :, :, 0]        # Ground Truth\n\n    # --- growth Intensity ---\n    pred_regen = np.abs(pred_frame - last_frame)\n    actual_regen = np.abs(actual_frame - last_frame)\n\n    # --- IoU ---\n    pred_mask = (pred_regen > 0.15).astype(float)\n    actual_mask = (actual_regen > 0.15).astype(float)\n    overlap = np.sum(pred_mask * actual_mask)\n    union = np.sum((pred_mask + actual_mask) > 0)\n    iou = overlap / union if union > 0 else 0\n\n    # --- COLUMN 1: PREDICTED GROWTH (Darker = Stronger) ---\n    pred_map = np.ones((128, 128, 3))  # White background\n    pred_norm = 1 - np.clip(pred_regen, 0, 1)  # Invert: black = high growth\n    pred_map[:, :, 0] = pred_norm\n    pred_map[:, :, 1] = pred_norm\n    pred_map[:, :, 2] = pred_norm\n    axes[row, 0].imshow(pred_map)\n    axes[row, 0].set_title(f'Sample {idx}\\nPREDICTED Growth\\n(Darker = Stronger)')\n    axes[row, 0].axis('off')\n\n    # --- COLUMN 2: ACTUAL GROWTH ---\n    actual_map = np.ones((128, 128, 3))\n    actual_norm = 1 - np.clip(actual_regen, 0, 1)\n    actual_map[:, :, 0] = actual_norm\n    actual_map[:, :, 1] = actual_norm\n    actual_map[:, :, 2] = actual_norm\n    axes[row, 1].imshow(actual_map)\n    axes[row, 1].set_title(f'ACTUAL Growth\\nIoU: {iou:.3f}')\n    axes[row, 1].axis('off')\n\n    # --- COLUMN 3: ACCURACY MAP ---\n    diff_map = np.ones((128, 128, 3))\n    # Black = Correct (both predict growth)\n    both = (pred_regen > 0.15) & (actual_regen > 0.15)\n    diff_map[both] = [0.0, 0.0, 0.0]\n    # Dark Gray = Over-prediction\n    over = (pred_regen > 0.15) & (actual_regen <= 0.15)\n    diff_map[over] = [0.3, 0.3, 0.3]\n    # Light Gray = Under-prediction\n    under = (pred_regen <= 0.15) & (actual_regen > 0.15)\n    diff_map[under] = [0.7, 0.7, 0.7]\n    axes[row, 2].imshow(diff_map)\n    axes[row, 2].set_title('ACCURACY\\n(B=Correct, DG=Over, LG=Under)')\n    axes[row, 2].axis('off')\n\nplt.tight_layout()\nplt.show()\n\n# === SUMMARY ===\nious = []\nfor idx in random_indices:\n    seq = X_val[idx:idx+1]\n    pred = generator.predict(seq, verbose=0)\n    last = seq[0,3,:,:,0]\n    pred_regen = np.abs(pred[0,:,:,0] - last)\n    actual_regen = np.abs(y_val[idx,:,:,0] - last)\n    pred_mask = (pred_regen > 0.15)\n    actual_mask = (actual_regen > 0.15)\n    overlap = np.sum(pred_mask & actual_mask)\n    union = np.sum(pred_mask | actual_mask)\n    iou = overlap / union if union > 0 else 0\n    ious.append(iou)\n\nprint(f\"\\nAVERAGE IoU: {np.mean(ious):.3f} Â± {np.std(ious):.3f}\")\nprint(\"Model predicts real cell growth â€” NOT copying Frame 1!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-10T15:08:22.110253Z","iopub.execute_input":"2025-11-10T15:08:22.110941Z","iopub.status.idle":"2025-11-10T15:08:25.043430Z","shell.execute_reply.started":"2025-11-10T15:08:22.110910Z","shell.execute_reply":"2025-11-10T15:08:25.042559Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# VISUALIZE THE REAL OCCLUSION RESULTS\nprint(\"=== REAL FRAME IMPORTANCE VISUALIZATION ===\")\n\nocclusion_results = [0.357804, 0.059478, 0.051079, 0.030132]\nframes = ['Frame 1', 'Frame 2', 'Frame 3', 'Frame 4']\n\nplt.figure(figsize=(12, 6))\n\n# Bar chart\nplt.subplot(1, 2, 1)\nbars = plt.bar(frames, occlusion_results, color=['red', 'blue', 'blue', 'blue'])\nplt.title('Frame Occlusion Impact on Predictions')\nplt.ylabel('Prediction Change (MAE)')\nplt.xticks(rotation=45)\n\n# Make Frame 1 stand out\nbars[0].set_color('red')\nbars[0].set_alpha(0.8)\n\n# Ratio chart\nplt.subplot(1, 2, 2)\nratios = [occlusion_results[0] / x for x in occlusion_results[1:]]\nplt.bar(['vs Frame 2', 'vs Frame 3', 'vs Frame 4'], ratios, color='orange')\nplt.title('Frame 1 Importance Multiplier')\nplt.ylabel('Times More Important')\nplt.xticks(rotation=45)\n\nplt.tight_layout()\nplt.show()\n\nprint(f\"\\nKEY INSIGHTS:\")\nprint(f\"â€¢ Frame 1 is {occlusion_results[0]/occlusion_results[1]:.1f}x more important than Frame 2\")\nprint(f\"â€¢ Frame 1 is {occlusion_results[0]/occlusion_results[3]:.1f}x more important than Frame 4\")\nprint(f\"â€¢ Removing Frame 1 changes predictions by {occlusion_results[0]:.3f} MAE\")\nprint(f\"â€¢ Removing Frame 4 changes predictions by only {occlusion_results[3]:.3f} MAE\")\n\n# Show what this means biologically\nprint(f\"\\nðŸ”¬ BIOLOGICAL IMPLICATIONS:\")\nprint(f\"â€¢ growth fate is determined EARLY (Frame 1 timeframe)\")\nprint(f\"â€¢ Later observations provide minor refinements only\")\nprint(f\"â€¢ Your sampling strategy could focus on early timepoints\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-10T15:09:06.750152Z","iopub.execute_input":"2025-11-10T15:09:06.750762Z","iopub.status.idle":"2025-11-10T15:09:07.022942Z","shell.execute_reply.started":"2025-11-10T15:09:06.750742Z","shell.execute_reply":"2025-11-10T15:09:07.022162Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# === COMPACT OCCLUSION HEATMAP (SMALL IMAGES) ===\ninput_frames = X_test[0:1]\ntrue_next_frame = y_test[0:1]\nH, W = input_frames.shape[2:4]\npatch = 24\nstep = 12\nmaps = []\n\nfor f in range(4):\n    base_pred = generator.predict(input_frames, verbose=0)\n    base_mae = np.mean(np.abs(base_pred - true_next_frame))\n    heat = np.zeros((H, W))\n\n    for i in range(0, H - patch + 1, step):\n        for j in range(0, W - patch + 1, step):\n            x = input_frames.copy()\n            x[0, f, i:i+patch, j:j+patch, :] = 0\n            pred = generator.predict(x, verbose=0)\n            drop = np.mean(np.abs(pred - true_next_frame)) - base_mae\n            heat[i:i+patch, j:j+patch] += drop\n\n    heat = np.clip(heat, 0, None)\n    maps.append(heat)\n\n# === VISUALIZE: 4 FRAMES + HEATMAPS ===\nfig, ax = plt.subplots(2, 4, figsize=(10, 5), dpi=100)\nfor i in range(4):\n    ax[0,i].imshow(input_frames[0,i,:,:,0], cmap='gray')\n    ax[0,i].axis('off'); ax[0,i].set_title(f\"F{i+1}\")\n    im = ax[1,i].imshow(input_frames[0,i,:,:,0], cmap='gray', alpha=0.7)\n    ax[1,i].imshow(maps[i], cmap='hot', alpha=0.6)\n    ax[1,i].axis('off'); ax[1,i].set_title(f\"Learned (F{i+1})\")\n\nplt.subplots_adjust(wspace=0.05, hspace=0.1)\ncbar = fig.colorbar(im, ax=ax, location='bottom', fraction=0.05, pad=0.05)\ncbar.set_label('Î”MAE when region is hidden')\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-10T15:20:05.649160Z","iopub.execute_input":"2025-11-10T15:20:05.649777Z","iopub.status.idle":"2025-11-10T15:20:29.295770Z","shell.execute_reply.started":"2025-11-10T15:20:05.649754Z","shell.execute_reply":"2025-11-10T15:20:29.295080Z"}},"outputs":[],"execution_count":null}]}